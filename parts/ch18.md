# Chapter 18. 모니터링과 관측 가능성

배포 후 운영 환경에서 리액티브 애플리케이션을 안정적으로 관리하는 일은 생각보다 복잡하다. 그래서 우리에게는 세 가지 핵심 관측 가능성(Observability) 축이 필요한 것인데, 바로 **메트릭(Metrics)**, **트레이스(Traces)**, **로그(Logs)**다.

특히 WebFlux의 경우 전통적인 서블릿 기반 애플리케이션과는 다르다. 하나의 요청이 여러 스레드를 넘나들며 처리되기 때문에, 단순한 `ThreadLocal` 기반의 기존 모니터링 방식으로는 충분하지 않다.

이 장에서는 실제 운영 환경에 필요한 관측 가능성을 어떻게 구축할지 배워볼 것이다. Spring Boot Actuator로 메트릭을 노출하는 것부터 시작해서, Micrometer와 Prometheus로 수집하고, Grafana로 시각화하는 전체 파이프라인을 함께 구성해보자. 그리고 Reactor 스트림 내부에서 메트릭을 수집하는 방법, 분산 추적(Zipkin/Jaeger) 구성, 그리고 리액티브 환경에 맞춘 구조화된 로깅까지 실전에서 필요한 전략들을 차근차근 살펴보겠다.

---

## 18.1 Spring Boot Actuator 설정

### 18.1.1 Actuator 소개와 의존성

Spring Boot Actuator는 애플리케이션의 상태, 메트릭, 환경 정보 같은 것들을 HTTP 엔드포인트로 손쉽게 노출할 수 있게 해주는 운영 도구 모듈이다. WebFlux 환경에서도 동일하게 동작하며, 무엇보다 리액티브 기반의 Health Indicator를 제공한다는 점이 중요하다.

```groovy
dependencies {
    implementation 'org.springframework.boot:spring-boot-starter-webflux'
    implementation 'org.springframework.boot:spring-boot-starter-data-mongodb-reactive'
    implementation 'org.springframework.boot:spring-boot-starter-actuator'
}
```

### 18.1.2 엔드포인트 활성화와 노출 설정

Actuator를 처음 설정할 때 주의할 점이 하나 있는데, 기본적으로 대부분의 엔드포인트는 활성화되지만 HTTP로 노출되는 것은 `health`뿐이라는 것이다. 따라서 운영에 필요한 엔드포인트를 선택적으로 노출해야 한다.

```yaml
# application.yml
management:
  endpoints:
    web:
      exposure:
        include: health, info, metrics, prometheus, env, loggers
      base-path: /actuator
  endpoint:
    health:
      show-details: when_authorized
      show-components: when_authorized
    info:
      enabled: true
  info:
    env:
      enabled: true
    java:
      enabled: true
    os:
      enabled: true
```

주요 엔드포인트는 다음과 같다.

| 엔드포인트 | 경로 | 설명 |
|-----------|------|------|
| **health** | `/actuator/health` | 애플리케이션 및 의존 서비스 상태 |
| **info** | `/actuator/info` | 애플리케이션 정보 (버전, Git 커밋 등) |
| **metrics** | `/actuator/metrics` | Micrometer 기반 메트릭 목록 |
| **prometheus** | `/actuator/prometheus` | Prometheus 형식의 메트릭 |
| **loggers** | `/actuator/loggers` | 런타임 로그 레벨 변경 |

### 18.1.3 커스텀 Health Indicator

MongoDB Reactive 스타터를 사용하면 `ReactiveMongoHealthIndicator`가 자동으로 등록되어 매우 편하다. 그런데 외부 결제 서비스라던가, 자동 감지되지 않는 외부 서비스의 상태를 확인하려면? 이럴 때는 `ReactiveHealthIndicator`를 직접 구현해서 처리해야 한다.

```java
@Component
public class ExternalPaymentServiceHealthIndicator
        implements ReactiveHealthIndicator {

    private final WebClient paymentClient;

    public ExternalPaymentServiceHealthIndicator(
            @Qualifier("paymentServiceClient") WebClient paymentClient) {
        this.paymentClient = paymentClient;
    }

    @Override
    public Mono<Health> health() {
        return paymentClient.get()
            .uri("/health")
            .retrieve()
            .bodyToMono(String.class)
            .map(response -> Health.up()
                .withDetail("service", "payment-api").build())
            .onErrorResume(ex -> Mono.just(Health.down()
                .withDetail("service", "payment-api")
                .withDetail("error", ex.getMessage()).build()))
            .timeout(Duration.ofSeconds(3),
                Mono.just(Health.down()
                    .withDetail("error", "Health check timed out").build()));
    }
}
```

### 18.1.4 Actuator 보안 설정

Actuator 엔드포인트를 운영 환경에 배포할 때 반드시 신경 써야 할 부분이 보안이다. 엔드포인트에는 민감한 정보들이 포함될 수 있으니까, Spring Security WebFlux와 연동하여 접근을 제한하는 것이 필수다.

```java
@Configuration
@EnableWebFluxSecurity
public class ActuatorSecurityConfig {

    @Bean
    public SecurityWebFilterChain securityWebFilterChain(
            ServerHttpSecurity http) {
        return http
            .authorizeExchange(exchanges -> exchanges
                .pathMatchers("/actuator/health", "/actuator/info").permitAll()
                .pathMatchers("/actuator/prometheus").hasRole("MONITORING")
                .pathMatchers("/actuator/**").hasRole("ADMIN")
                .pathMatchers("/api/**").authenticated()
                .anyExchange().permitAll()
            )
            .httpBasic(Customizer.withDefaults())
            .csrf(csrf -> csrf.disable())
            .build();
    }
}
```

더 나아가, 운영 환경에서는 Actuator 포트를 애플리케이션 포트와 완전히 분리하는 방식을 강력히 권장한다.

```yaml
# application-prod.yml
management:
  server:
    port: 9090
  endpoints:
    web:
      exposure:
        include: health, prometheus
```

이 방식을 사용하면 애플리케이션은 8080 포트에서, Actuator는 9090 포트에서 서비스되므로, 방화벽 규칙으로 내부 네트워크만 접근 가능하도록 제한할 수 있다는 이점이 있다.

---

## 18.2 Micrometer와 Prometheus 연동

### 18.2.1 Micrometer 소개

Micrometer를 처음 들을 때, 사람들은 보통 "또 다른 라이브러리?"라고 생각한다. 그런데 이것은 정말 훌륭한 설계다. 흔히 말하는 **벤더 중립적 메트릭 파사드**로서, SLF4J가 로깅 구현체를 추상화하는 것처럼, Micrometer는 Prometheus, Datadog, CloudWatch 등 메트릭 수집 구현체를 모두 추상화한다. Spring Boot Actuator는 내부적으로 이 Micrometer를 활용하고 있으니, 우리가 제대로 이해하고 사용해야 할 필요가 있다.

```groovy
dependencies {
    implementation 'org.springframework.boot:spring-boot-starter-actuator'
    implementation 'io.micrometer:micrometer-registry-prometheus'
}
```

위 의존성을 추가하면 `/actuator/prometheus` 엔드포인트가 자동으로 활성화된다.

### 18.2.2 자동 수집 메트릭

설정을 하면, Spring Boot와 Micrometer가 자동으로 많은 메트릭을 수집해준다는 점이 정말 편하다. 별도의 코드 없이도 다양한 메트릭이 자동으로 수집되기 때문이다.

| 카테고리 | 메트릭 예시 | 설명 |
|---------|-----------|------|
| **JVM** | `jvm_memory_used_bytes` | 힙/논힙 메모리 사용량 |
| **JVM** | `jvm_gc_pause_seconds` | GC 일시 정지 시간 |
| **HTTP** | `http_server_requests_seconds` | HTTP 요청 처리 시간 (uri, method, status별) |
| **MongoDB** | `mongodb_driver_pool_size` | MongoDB 커넥션 풀 크기 |
| **MongoDB** | `mongodb_driver_commands_seconds` | MongoDB 명령 실행 시간 |
| **System** | `system_cpu_usage` | 시스템 CPU 사용률 |

### 18.2.3 커스텀 메트릭 -- Counter

이제 본격적으로 메트릭을 직접 정의해서 사용해보자. 가장 간단한 형태인 `Counter`부터 시작하면, 이것은 단조 증가하는 값을 추적한다. 주문 건수, 에러 발생 횟수 같은 것들을 기록할 때 매우 유용하다.

```java
@Service
@RequiredArgsConstructor
public class OrderService {

    private final OrderRepository orderRepository;
    private final MeterRegistry meterRegistry;

    public Mono<Order> createOrder(OrderRequest request) {
        return orderRepository.save(Order.from(request))
            .doOnSuccess(order ->
                Counter.builder("orders.created")
                    .description("총 생성된 주문 수")
                    .tag("category", order.getCategory())
                    .tag("payment_method", order.getPaymentMethod())
                    .register(meterRegistry)
                    .increment())
            .doOnError(ex ->
                Counter.builder("orders.failed")
                    .description("주문 실패 수")
                    .tag("error_type", ex.getClass().getSimpleName())
                    .register(meterRegistry)
                    .increment());
    }
}
```

### 18.2.4 커스텀 메트릭 -- Gauge

`Gauge`는 Counter와 달리, 현재 시점의 값을 나타낸다. 대기열 크기, 활성 연결 수처럼 증가했다 감소했다를 반복하는 값에 사용하면 좋다.

```java
@Component
public class QueueMetrics {

    private final AtomicInteger pendingTaskCount = new AtomicInteger(0);

    public QueueMetrics(MeterRegistry meterRegistry) {
        Gauge.builder("tasks.pending", pendingTaskCount, AtomicInteger::get)
            .description("처리 대기 중인 작업 수")
            .register(meterRegistry);
    }

    public void taskAdded() { pendingTaskCount.incrementAndGet(); }
    public void taskCompleted() { pendingTaskCount.decrementAndGet(); }
}
```

### 18.2.5 커스텀 메트릭 -- Timer

마지막으로 소개할 `Timer`는 실무에서 정말 자주 쓰이는 메트릭인데, 작업의 소요 시간과 호출 횟수를 동시에 기록한다. 성능 분석에 필수적이고, 필자의 경험상 성능 문제를 추적할 때 가장 먼저 확인하는 메트릭이다.

```java
@Service
@RequiredArgsConstructor
public class ProductSearchService {

    private final ReactiveMongoTemplate mongoTemplate;
    private final MeterRegistry meterRegistry;

    public Flux<Product> search(String keyword) {
        Timer.Sample sample = Timer.start(meterRegistry);

        return mongoTemplate.find(
                new Query(Criteria.where("name").regex(keyword, "i")),
                Product.class)
            .doFinally(signalType ->
                sample.stop(Timer.builder("product.search.duration")
                    .description("상품 검색 소요 시간")
                    .tag("signal", signalType.name())
                    .publishPercentiles(0.5, 0.95, 0.99)
                    .publishPercentileHistogram()
                    .register(meterRegistry)));
    }
}
```

`publishPercentiles`로 p50, p95, p99 레이턴시를 Grafana에서 바로 확인할 수 있다.

### 18.2.6 공통 태그와 메트릭 사전 등록

모든 메트릭에 공통적으로 적용할 태그가 있다면, 중복 코드 대신 한 곳에서 관리하자.

```java
@Configuration
public class MetricsConfig {

    @Bean
    public MeterRegistryCustomizer<MeterRegistry> commonTags() {
        return registry -> registry.config()
            .commonTags(
                "application", "webflux-shop",
                "environment", System.getenv().getOrDefault("ENV", "local")
            );
    }

    @Bean
    public Timer externalApiTimer(MeterRegistry registry) {
        return Timer.builder("external.api.duration")
            .description("외부 API 호출 소요 시간")
            .publishPercentiles(0.5, 0.95, 0.99)
            .register(registry);
    }
}
```

### 18.2.7 Prometheus 설정 (prometheus.yml)

이제 Prometheus가 우리 애플리케이션의 메트릭을 주기적으로 수집하도록 설정해야 한다.

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'webflux-app'
    metrics_path: '/actuator/prometheus'
    scrape_interval: 10s
    static_configs:
      - targets: ['host.docker.internal:8080']
        labels:
          app: 'webflux-shop'
          env: 'development'

  - job_name: 'webflux-cluster'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets:
          - 'webflux-app-1:9090'
          - 'webflux-app-2:9090'
          - 'webflux-app-3:9090'
```

그리고 Docker Compose로 Prometheus를 실행하면 되는데, 제대로 설정되었는지 확인하려면 Prometheus UI(`http://localhost:9090`)에서 `up{job="webflux-app"}` 쿼리를 실행해서 타겟 연결 상태를 확인하면 된다.

```yaml
# docker-compose-monitoring.yml
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
```

---

## 18.3 Grafana 대시보드 구성

### 18.3.1 Grafana Docker 설치와 데이터소스 연결

Prometheus에서 수집한 메트릭을 이제 시각화해야 한다. 기존 `docker-compose-monitoring.yml`에 Grafana를 추가하자.

```yaml
services:
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin123
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
```

`docker compose -f docker-compose-monitoring.yml up -d`로 실행하고, `http://localhost:3000`에 접속해서 로그인하면 된다. Grafana의 프로비저닝 기능을 사용하면 Prometheus 데이터소스를 자동으로 등록할 수 있다.

```yaml
# grafana/provisioning/datasources/prometheus.yml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
```

### 18.3.3 대시보드 임포트

Grafana 커뮤니티에서 이미 만들어놓은 훌륭한 대시보드들이 있다. 이걸 임포트하면 처음부터 모두 직접 만들 필요 없이 빠르게 모니터링 환경을 구축할 수 있으니, 실무에서 자주 활용하면 좋다.

| 대시보드 ID | 이름 | 용도 |
|------------|------|------|
| **4701** | JVM (Micrometer) | JVM 메모리, GC, 스레드 모니터링 |
| **11378** | Spring Boot Statistics | HTTP 요청, 에러율, 응답 시간 |
| **12900** | Spring Boot Observability | 종합 관측 가능성 |

Grafana UI에서 **Dashboards > Import** 메뉴로 이동하여 대시보드 ID를 입력하면 된다.

### 18.3.4 커스텀 대시보드 PromQL 쿼리

프로젝트에 맞게 커스텀 패널을 만들어야 할 때가 분명히 온다. 그럴 때를 위해 자주 사용하는 PromQL 쿼리들을 정리해놨으니, 필요할 때 참고하자.

**초당 요청 수 (RPS)**:
```promql
rate(http_server_requests_seconds_count{application="webflux-shop"}[5m])
```

**95번째 백분위 응답 시간**:
```promql
histogram_quantile(0.95,
  rate(http_server_requests_seconds_bucket{application="webflux-shop"}[5m]))
```

**에러율 (%)**:
```promql
sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m]))
/
sum(rate(http_server_requests_seconds_count[5m]))
* 100
```

### 18.3.5 알림 규칙 설정

대시보드를 만들었으면 이제 문제 상황을 자동으로 감지하고 알려주는 알림 기능을 설정해야 한다. Grafana의 알림 기능을 사용하면 Slack, Email, PagerDuty 등으로 문제를 바로 알릴 수 있다. Grafana UI의 **Alerting > Alert Rules > New alert rule**에서 생성하면 되며, 주요 설정 항목은 다음과 같다.

| 설정 항목 | 값 | 설명 |
|----------|---|------|
| **Rule name** | 높은 에러율 경고 | 알림 규칙 이름 |
| **Query** | 위 에러율 PromQL | 감시 대상 쿼리 |
| **Threshold** | `> 5` | 에러율 5% 초과 시 |
| **Pending period** | `5m` | 5분간 지속 시 알림 발생 |

알림 채널은 **Alerting > Contact points**에서 설정한다.

---

## 18.4 리액티브 스트림 메트릭 수집

### 18.4.1 Reactor 메트릭 활성화

Reactor는 Micrometer와 깊게 통합되어 있는데, 내장 메트릭 기능을 제공한다. 이 기능을 활성화하면 Reactor 파이프라인 내부의 구독 상태, 요청 수, 에러 등을 추적할 수 있으니 매우 유용하다.

```java
@SpringBootApplication
public class WebFluxApplication {

    public static void main(String[] args) {
        Hooks.enableAutomaticContextPropagation();
        Schedulers.enableMetrics();
        SpringApplication.run(WebFluxApplication.class, args);
    }
}
```

### 18.4.2 개별 연산자 메트릭 수집

특정 Reactor 체인에 대해 더 세밀한 메트릭을 수집하려면 `.name()`과 `.tag()` 연산자를 활용하면 된다. 그리고 체인 끝에 `.metrics()`를 추가하면 해당 시점까지의 모든 메트릭이 Micrometer로 자동 기록된다.

```java
@Service
@RequiredArgsConstructor
public class NotificationService {

    private final ReactiveMongoTemplate mongoTemplate;

    public Flux<Notification> getUnreadNotifications(String userId) {
        return mongoTemplate.find(
                Query.query(Criteria.where("userId").is(userId)
                    .and("read").is(false)),
                Notification.class)
            .name("notification.unread.fetch")
            .tag("type", "unread")
            .metrics();
    }
}
```

이렇게 구성하면 다음과 같은 메트릭이 자동으로 생성되는데, 한번 생기면 Grafana에서 바로 확인할 수 있다.

| 메트릭 이름 | 설명 |
|------------|------|
| `reactor.notification.unread.fetch.subscribed` | 구독 횟수 |
| `reactor.notification.unread.fetch.requested` | 요청된 요소 수 |
| `reactor.notification.unread.fetch.onNext.delay` | onNext 신호 간의 지연 시간 |
| `reactor.notification.unread.fetch.flow.duration` | 전체 실행 시간 |

### 18.4.3 Schedulers 메트릭

스레드 풀 성능을 모니터링할 필요가 있을 때는 `Schedulers.enableMetrics()` 호출 후 다음 메트릭들이 수집된다.

| 메트릭 | 설명 |
|--------|------|
| `executor_pool_size_threads` | 현재 스레드 풀 크기 |
| `executor_active_threads` | 활성 스레드 수 |
| `executor_queued_tasks` | 대기열 태스크 수 |
| `executor_completed_tasks_total` | 완료된 태스크 수 |

만약 여러 개의 스케줄러를 사용하고 있다면, 각 스케줄러에 이름을 부여해서 생성하면 스케줄러별로 메트릭을 구분하여 모니터링할 수 있다는 점이 도움이 된다.

```java
@Configuration
public class SchedulerMetricsConfig {

    @Bean
    public Scheduler metricsEnabledBoundedElastic() {
        return Schedulers.newBoundedElastic(
            Schedulers.DEFAULT_BOUNDED_ELASTIC_SIZE,
            Schedulers.DEFAULT_BOUNDED_ELASTIC_QUEUESIZE,
            "custom-bounded-elastic"
        );
    }
}
```

---

## 18.5 분산 추적 (Zipkin / Jaeger)

### 18.5.1 분산 추적의 필요성

우리의 애플리케이션이 점점 커지고 마이크로서비스 구조로 변하면, 하나의 사용자 요청이 수십 개의 서비스를 거쳐 처리되는 일이 생긴다. 이런 상황에서 "어디서 느려졌어?"라는 질문에 답하기 위해서는 분산 추적이 필수다. 분산 추적은 **Trace ID**와 **Span ID**로 요청 전체의 호출 흐름을 연결해서 보여준다.

```
[사용자 요청]
  └─ Trace ID: abc123
      ├─ Span 1: API Gateway (10ms)
      ├─ Span 2: Product Service (25ms)
      │   └─ Span 3: MongoDB 쿼리 (8ms)
      └─ Span 4: Order Service (30ms)
          └─ Span 5: Payment API 호출 (20ms)
```

### 18.5.2 Micrometer Tracing 설정

Spring Boot 3.x부터는 분산 추적의 표준으로 Micrometer Tracing을 사용한다. 이것이 좋은 이유는 Brave(Zipkin) 또는 OpenTelemetry 브릿지 중 원하는 것을 선택해서 사용할 수 있다는 유연성이다.

**Zipkin을 사용하는 경우**:

```groovy
dependencies {
    implementation 'io.micrometer:micrometer-tracing-bridge-brave'
    implementation 'io.zipkin.reporter2:zipkin-reporter-brave'
}
```

**Jaeger를 사용하는 경우 (OpenTelemetry)**:

```groovy
dependencies {
    implementation 'io.micrometer:micrometer-tracing-bridge-otel'
    implementation 'io.opentelemetry:opentelemetry-exporter-zipkin'
}
```

> **참고**: Jaeger는 Zipkin 호환 프로토콜을 지원하므로, Zipkin 리포터로도 Jaeger에 데이터를 전송할 수 있다. 최신 Jaeger는 OTLP(OpenTelemetry Protocol)를 기본 수집 프로토콜로 권장한다.

### 18.5.3 application.yml 설정

설정은 상당히 간단한데, 주의할 점은 `sampling.probability`다. 개발 환경에서는 100%로 설정하고, 운영에서는 필자의 경험상 10% 정도로 줄이는 것이 좋다. 그래야 Zipkin 스토리지에 부담을 주지 않으면서도 충분한 샘플을 수집할 수 있기 때문이다.

```yaml
management:
  tracing:
    sampling:
      probability: 1.0        # 개발: 100%, 운영: 0.1 (10%) 권장
    propagation:
      type: b3                 # W3C 또는 B3 전파 형식
  zipkin:
    tracing:
      endpoint: http://localhost:9411/api/v2/spans

logging:
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] [%X{traceId}/%X{spanId}] %-5level %logger{36} - %msg%n"
```

### 18.5.4 Zipkin / Jaeger Docker 설치

Zipkin은 정말 간단하게 `docker run -d -p 9411:9411 openzipkin/zipkin`으로 실행할 수 있다. Jaeger를 사용하려면 다음과 같이 설정하면 된다.

```yaml
services:
  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"    # Jaeger UI
      - "9411:9411"      # Zipkin 호환 포트
      - "4317:4317"      # OTLP gRPC
    environment:
      COLLECTOR_ZIPKIN_HOST_PORT: ":9411"
```

Zipkin UI는 `http://localhost:9411`, Jaeger UI는 `http://localhost:16686`에서 접근한다.

### 18.5.5 WebClient에서의 Trace 전파

외부 서비스를 호출할 때 trace 정보가 자동으로 전파되게 하려면, `WebClient`를 `WebClient.Builder` 빈으로 생성해야 한다. 그러면 Micrometer Tracing이 자동으로 Trace 전파 필터를 추가한다. 여기서 중요한 팁은 `WebClient.create()`를 사용하면 안 되고, 반드시 스프링이 관리하는 `WebClient.Builder`를 주입받아 사용해야 한다는 것이다.

```java
@Configuration
public class WebClientConfig {

    @Bean
    public WebClient externalServiceClient(WebClient.Builder builder) {
        // Builder 빈을 주입받으면 Tracing 필터가 자동 추가됨
        return builder
            .baseUrl("https://external-service.example.com")
            .build();
    }
}
```

이렇게 생성한 `WebClient`로 외부 API를 호출하면, Trace ID가 자동으로 요청 헤더에 포함된다. 나중에 Zipkin UI에서 트레이스를 조회해보면 MongoDB 조회, 외부 API 호출 같은 여러 작업이 각각 별도의 Span으로 기록되면서도, 동일한 Trace ID로 하나로 연결되어 있는 것을 확인할 수 있다. 이것이 분산 추적의 진정한 가치다.

### 18.5.6 커스텀 Span 생성

자동 계측만으로는 충분하지 않을 때도 있다. 특정 메서드나 로직 블록의 성능을 더 상세하게 추적해야 한다면, `@Observed` 어노테이션으로 메서드 단위 Span을 직접 생성하거나, `Observation` API를 사용해서 더 세밀하게 제어할 수 있다.

```java
@Service
public class InventoryService {

    @Observed(name = "inventory.check",
              contextualName = "check-inventory",
              lowCardinalityKeyValues = {"inventory.type", "product"})
    public Mono<Boolean> checkAvailability(String productId, int quantity) {
        return Mono.just(true);
    }
}
```

`@Observed`를 사용하려면 `ObservedAspect` 빈을 등록해야 한다.

```java
@Configuration
public class ObservationConfig {

    @Bean
    public ObservedAspect observedAspect(ObservationRegistry registry) {
        return new ObservedAspect(registry);
    }
}
```

`Observation` API를 사용하면 리액티브 체인 내에서 더 세밀한 Span 제어가 가능하다.

```java
@Service
@RequiredArgsConstructor
public class PaymentProcessService {

    private final ObservationRegistry observationRegistry;

    public Mono<PaymentResult> processPayment(PaymentRequest request) {
        Observation observation = Observation.createNotStarted(
                "payment.process", observationRegistry)
            .lowCardinalityKeyValue("payment.method", request.getPaymentMethod());

        return Mono.just(request)
            .flatMap(this::validatePayment)
            .flatMap(this::executePayment)
            .doOnSubscribe(s -> observation.start())
            .doOnTerminate(observation::stop)
            .doOnError(observation::error);
    }
}
```

---

## 18.6 구조화된 로깅 (Logback + MDC in Reactive)

### 18.6.1 구조화된 로깅의 필요성

로그를 파일에 저장해뒀다가 나중에 문제를 분석하려면, 텍스트 기반 로그로는 원하는 정보를 찾기가 정말 어렵다. 검색도 어렵고 집계도 안 된다. 그래서 운영 환경에서는 ELK(Elasticsearch + Logstash + Kibana)나 Loki 같은 로그 수집 시스템과 연동하는데, 이 경우 **JSON 형식** 로그가 효과적이다.

```
# 기존 텍스트 로그
2026-02-14 10:30:15.123 [reactor-http-nio-3] INFO c.e.s.OrderService - 주문 생성 완료: orderId=abc123
```

```json
// 구조화된 JSON 로그
{
  "timestamp": "2026-02-14T10:30:15.123Z",
  "level": "INFO",
  "logger": "com.example.shop.OrderService",
  "message": "주문 생성 완료",
  "traceId": "6a3f7b2c1d4e5f",
  "spanId": "a1b2c3d4",
  "orderId": "abc123",
  "userId": "user-456",
  "service": "webflux-shop"
}
```

### 18.6.2 Logback JSON 설정

로그를 JSON 형식으로 만들려면 `logstash-logback-encoder` 라이브러리를 사용하면 된다. 매우 편하다.

```groovy
dependencies {
    implementation 'net.logstash.logback:logstash-logback-encoder:7.4'
}
```

```xml
<!-- src/main/resources/logback-spring.xml -->
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <springProperty scope="context" name="APP_NAME"
                    source="spring.application.name" defaultValue="webflux-app"/>

    <!-- 개발 환경: 텍스트 로그 -->
    <springProfile name="local,dev">
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <encoder>
                <pattern>%d{HH:mm:ss.SSS} [%thread] [%X{traceId:-}/%X{spanId:-}] %-5level %logger{36} - %msg%n</pattern>
            </encoder>
        </appender>
        <root level="INFO"><appender-ref ref="CONSOLE"/></root>
    </springProfile>

    <!-- 운영 환경: JSON 로그 -->
    <springProfile name="prod,staging">
        <appender name="JSON_CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <encoder class="net.logstash.logback.encoder.LogstashEncoder">
                <includeMdcKeyName>traceId</includeMdcKeyName>
                <includeMdcKeyName>spanId</includeMdcKeyName>
                <includeMdcKeyName>userId</includeMdcKeyName>
                <includeMdcKeyName>requestId</includeMdcKeyName>
                <customFields>{"service":"${APP_NAME}"}</customFields>
                <timeZone>UTC</timeZone>
            </encoder>
        </appender>
        <root level="INFO"><appender-ref ref="JSON_CONSOLE"/></root>
    </springProfile>
</configuration>
```

### 18.6.3 리액티브 환경에서의 MDC 문제와 해결

전통적인 서블릿 애플리케이션에서는 MDC(Mapped Diagnostic Context)가 `ThreadLocal` 기반으로 동작하기 때문에 각 요청별로 로그를 추적하는 것이 쉽다. 그런데 리액티브 환경은 다르다. 하나의 요청이 여러 스레드를 넘나들며 처리되기 때문에, `publishOn()`이나 `subscribeOn()`으로 스레드가 전환되면 기존 MDC 값이 유실되는 문제가 생긴다.

Spring Boot 3.x부터는 `context-propagation` 라이브러리와 `Hooks.enableAutomaticContextPropagation()`을 사용해서 이 문제를 깔끔하게 해결할 수 있다. 18.4.1에서 설정한 것처럼 이것을 활성화하면 `traceId`와 `spanId`가 자동으로 MDC에 전파된다. 만약 `userId`나 `requestId` 같은 비즈니스 컨텍스트를 추가로 전파하려면, `WebFilter`와 `ThreadLocalAccessor`를 구현해서 처리하면 된다.

### 18.6.4 커스텀 컨텍스트 전파

이제 실제로 구현해보자. `WebFilter`에서 Reactor Context에 값을 저장하고, `ThreadLocalAccessor`를 통해 MDC와 자동으로 연결하면 된다.

```java
@Component
@Order(Ordered.HIGHEST_PRECEDENCE)
public class ContextPropagationFilter implements WebFilter {

    @Override
    public Mono<Void> filter(ServerWebExchange exchange,
                             WebFilterChain chain) {
        String requestId = Optional.ofNullable(
                exchange.getRequest().getHeaders().getFirst("X-Request-Id"))
            .orElse(UUID.randomUUID().toString().substring(0, 12));

        return exchange.getPrincipal()
            .map(Principal::getName)
            .defaultIfEmpty("anonymous")
            .flatMap(userId -> chain.filter(exchange)
                .contextWrite(ctx -> ctx
                    .put("requestId", requestId)
                    .put("userId", userId)));
    }
}
```

그 다음, `ThreadLocalAccessor`를 구현해서 Reactor Context와 MDC 간의 자동 전파를 설정한다.

```java
public class UserIdThreadLocalAccessor implements ThreadLocalAccessor<String> {

    public static final String KEY = "userId";

    @Override
    public Object key() { return KEY; }

    @Override
    public String getValue() { return MDC.get(KEY); }

    @Override
    public void setValue(String value) { MDC.put(KEY, value); }

    @Override
    public void reset() { MDC.remove(KEY); }
}
```

`ThreadLocalAccessor` 구현체는 `ContextRegistry`에 등록하면 자동으로 작동한다. `requestId`도 `userId`와 동일한 패턴으로 구현해서 등록하면 되니까 복잡하지 않다.

```java
@Configuration
public class ContextPropagationConfig {

    @PostConstruct
    public void init() {
        ContextRegistry.getInstance()
            .registerThreadLocalAccessor(new UserIdThreadLocalAccessor());
        ContextRegistry.getInstance()
            .registerThreadLocalAccessor(new RequestIdThreadLocalAccessor());
    }
}
```

이 설정을 마치면, 스레드가 몇 번 전환되더라도 `userId`와 `requestId`가 MDC에 자동으로 전파되고, 결국 JSON 로그에 모두 포함되게 된다.

### 18.6.5 구조화된 로그 작성 패턴

마지막으로, 실제로 로그를 작성할 때는 `logstash-logback-encoder`의 `StructuredArguments`를 사용하면 로그 메시지와 JSON 필드를 동시에 기록할 수 있다. 이렇게 하면 나중에 Kibana에서 필드 기반으로 검색하고 집계하기가 훨씬 쉬워진다.

```java
import static net.logstash.logback.argument.StructuredArguments.*;

@Service
@Slf4j
@RequiredArgsConstructor
public class OrderService {

    private final OrderRepository orderRepository;

    public Mono<Order> createOrder(OrderRequest request) {
        return orderRepository.save(Order.from(request))
            .doOnSuccess(order ->
                log.info("주문 생성 완료: {} {} {}",
                    keyValue("orderId", order.getId()),
                    keyValue("amount", order.getTotalAmount()),
                    keyValue("items", order.getItems().size())))
            .doOnError(ex ->
                log.error("주문 생성 실패: {} {}",
                    keyValue("userId", request.getUserId()),
                    keyValue("error", ex.getMessage()), ex));
        // JSON: {"message":"주문 생성 완료: orderId=abc amount=15000 items=3",
        //        "orderId":"abc", "amount":15000, "items":3, ...}
    }
}
```

---

## 요약

이 장에서 다룬 내용을 정리하면 다음과 같다.

| 주제 | 핵심 내용 |
|------|----------|
| **Actuator** | `health`, `info`, `metrics`, `prometheus` 엔드포인트 노출, `ReactiveHealthIndicator`로 논블로킹 상태 확인, 포트 분리와 Security 연동으로 보안 강화 |
| **Micrometer + Prometheus** | `Counter`(단조 증가), `Gauge`(현재 값), `Timer`(소요 시간 + 호출 수) 커스텀 메트릭, `prometheus.yml`로 스크래핑 설정 |
| **Grafana** | Docker 설치, Prometheus 데이터소스 프로비저닝, 커뮤니티 대시보드 임포트, PromQL로 커스텀 패널, 알림 규칙 설정 |
| **리액티브 메트릭** | `.name().tag().metrics()`로 Reactor 체인 메트릭 수집, `Schedulers.enableMetrics()`로 스케줄러 모니터링 |
| **분산 추적** | Micrometer Tracing + Brave(Zipkin) 또는 OpenTelemetry(Jaeger), `WebClient.Builder` 빈으로 자동 Trace 전파, `@Observed`로 커스텀 Span |
| **구조화된 로깅** | `logstash-logback-encoder`로 JSON 로그, `Hooks.enableAutomaticContextPropagation()`으로 Reactor Context-MDC 자동 전파, `ThreadLocalAccessor`로 커스텀 컨텍스트 전파 |

다음 장에서는 완성된 애플리케이션의 성능을 어떻게 측정하고 최적화할지 배워보겠다. MongoDB 커넥션 풀 튜닝부터 시작해서, Netty 이벤트 루프 최적화, 캐싱, BlockHound를 활용한 블로킹 코드 탐지, 그리고 Gatling과 k6를 이용한 실전 부하 테스트까지 다룰 것이다.
