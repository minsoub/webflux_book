# Chapter 8. MongoDB 리액티브 데이터 접근 심화

Chapter 6에서 `ReactiveMongoRepository`의 기본 CRUD 구현을 다뤘으니, 이제 더 복잡한 실무 요구사항에 대응할 차례다. 이 장에서 중심을 두는 것은 `ReactiveMongoTemplate`인데, 이것이 있어야만 MongoDB의 고급 기능을 리액티브 방식으로 제대로 활용할 수 있다. 동적 쿼리 구성(Criteria API), 복잡한 통계 작업(Aggregation Pipeline), 데이터 변경 감시(Change Streams), 트랜잭션 처리, 인덱스 설계와 성능 최적화 같은 실전 주제들을 다루면서, 프로덕션 환경에서 실제로 마주치는 시나리오에 집중해보자.

---

## 8.1 ReactiveMongoTemplate 활용

### 8.1.1 ReactiveMongoTemplate vs ReactiveMongoRepository

`ReactiveMongoRepository`는 정말 편하다. 메서드 이름만 써도 쿼리가 자동으로 생성되고 기본 CRUD도 다 제공한다. 하지만 복잡한 조건의 쿼리, 특정 필드만 선택적으로 수정해야 하는 경우, 통계나 집계, 그리고 데이터 변경을 실시간으로 감시해야 하는 요구사항이 생기면 `ReactiveMongoTemplate`이 필요해진다. 필자의 경험상 프로덕션 시스템에서는 이 둘을 조합해서 쓰는 것이 가장 효율적이다.

| 비교 항목 | ReactiveMongoRepository | ReactiveMongoTemplate |
|-----------|------------------------|----------------------|
| **추상화 수준** | 높음 (인터페이스 선언만으로 사용) | 낮음 (직접 Query/Update 객체 구성) |
| **기본 CRUD** | 자동 제공 | 직접 구현 |
| **부분 업데이트** | 미지원 (전체 도큐먼트 교체) | `Update` 객체로 특정 필드만 수정 |
| **Upsert / Aggregation** | 미지원 | `upsert()`, `aggregate()` 제공 |
| **Change Streams** | 미지원 | `changeStream()` 메서드 제공 |
| **동적 쿼리** | 제한적 (`@Query` + SpEL) | `Criteria`로 자유롭게 조합 |

실제로 프로젝트에서 두 가지를 함께 사용할 때 패턴이 명확해진다. 간단한 CRUD 작업은 `ReactiveMongoRepository`로 깔끔하게 처리하고, 복잡한 쿼리나 특수한 요구사항이 있는 부분에서만 `ReactiveMongoTemplate`을 주입받아 사용하는 식이다.

### 8.1.2 ReactiveMongoTemplate 기본 CRUD

좋은 소식은 `ReactiveMongoTemplate`이 Spring Boot의 자동 설정에 포함되어 있다는 것이다. 따라서 특별한 설정 없이 주입받기만 하면 바로 사용할 수 있다.

```java
@Service
@RequiredArgsConstructor
public class ProductQueryService {

    private final ReactiveMongoTemplate mongoTemplate;

    public Flux<Product> findAll() {
        return mongoTemplate.findAll(Product.class);
    }

    public Mono<Product> findById(String id) {
        return mongoTemplate.findById(id, Product.class);
    }

    public Flux<Product> findByCategory(String category) {
        Query query = Query.query(Criteria.where("category").is(category));
        return mongoTemplate.find(query, Product.class);
    }

    public Mono<Product> insert(Product product) {
        return mongoTemplate.insert(product);
    }

    public Mono<DeleteResult> deleteById(String id) {
        Query query = Query.query(Criteria.where("id").is(id));
        return mongoTemplate.remove(query, Product.class);
    }
}
```

### 8.1.3 Query와 Update 객체

실제 쿼리를 작성할 때는 `Query` 객체와 `Update` 객체를 다루게 된다. 전자는 "어떤 도큐먼트를 찾을 것인가"를 정의하고, 후자는 "어떤 필드를 어떻게 수정할 것인가"를 담당한다.

```java
// 특정 필드만 업데이트 (부분 업데이트)
public Mono<UpdateResult> updatePrice(String productId, BigDecimal newPrice) {
    Query query = Query.query(Criteria.where("id").is(productId));
    Update update = new Update()
        .set("price", newPrice)
        .set("updatedAt", LocalDateTime.now());
    return mongoTemplate.updateFirst(query, update, Product.class);
}

// 조건에 맞는 모든 도큐먼트 업데이트
public Mono<UpdateResult> applyDiscount(String category, int discountPercent) {
    Query query = Query.query(Criteria.where("category").is(category));
    Update update = new Update()
        .mul("price", (100 - discountPercent) / 100.0)
        .set("updatedAt", LocalDateTime.now());
    return mongoTemplate.updateMulti(query, update, Product.class);
}
```

`Update` 객체의 주요 메서드는 다음과 같다.

| 메서드 | MongoDB 연산자 | 설명 |
|--------|---------------|------|
| `set(key, value)` | `$set` | 필드 값 설정 |
| `unset(key)` | `$unset` | 필드 제거 |
| `inc(key, value)` | `$inc` | 숫자 증가/감소 |
| `push(key, value)` | `$push` | 배열에 요소 추가 |
| `pull(key, value)` | `$pull` | 배열에서 요소 제거 |
| `addToSet(key, value)` | `$addToSet` | 배열에 중복 없이 추가 |
| `min(key, value)` / `max(key, value)` | `$min` / `$max` | 현재 값과 비교하여 갱신 |

### 8.1.4 Upsert와 findAndModify

여기서 정말 유용한 두 가지 패턴을 소개하려고 한다. 먼저 `upsert`는 "있으면 수정하고, 없으면 생성해"라는 요구사항을 한 번에 처리할 수 있는 원자적 연산이다. `findAndModify()`는 다르게, 도큐먼트를 수정한 후 그 결과를 바로 반환하기 때문에 "방금 수정한 상태"를 즉시 확인해야 할 때 쓸모가 있다. 필자의 경험상 이 두 메서드는 재고 관리나 카운터 증감 같은 시나리오에서 정말 자주 사용된다.

```java
// Upsert: 조회수 카운터 — 없으면 생성, 있으면 증가
public Mono<UpdateResult> incrementViewCount(String productId) {
    Query query = Query.query(Criteria.where("productId").is(productId));
    Update update = new Update()
        .inc("viewCount", 1)
        .setOnInsert("productId", productId)
        .setOnInsert("createdAt", LocalDateTime.now());
    return mongoTemplate.upsert(query, update, "product_views");
}

// findAndModify: 재고 차감 — 원자적으로 수행하고 수정된 결과 반환
public Mono<Product> decrementStock(String productId, int quantity) {
    Query query = Query.query(
        Criteria.where("id").is(productId).and("stock").gte(quantity)
    );
    Update update = new Update().inc("stock", -quantity);
    FindAndModifyOptions options = FindAndModifyOptions.options()
        .returnNew(true)
        .upsert(false);
    return mongoTemplate.findAndModify(query, update, options, Product.class);
}
```

`setOnInsert()`는 도큐먼트가 새로 삽입될 때만 적용되는 필드를 지정한다. MongoDB의 `$setOnInsert` 연산자에 대응한다.

---

## 8.2 커스텀 쿼리와 Criteria API

### 8.2.1 Criteria 기본 사용법

이제 본격적으로 동적 쿼리를 만들어보자. `Criteria`라는 클래스를 사용하면, MongoDB의 복잡한 쿼리 문법을 자바스럽게 빌더 패턴으로 구성할 수 있다.

```java
Criteria.where("category").is("electronics");       // 등호
Criteria.where("price").gte(10000).lte(50000);       // 범위
Criteria.where("description").exists(true);           // 존재 여부
Criteria.where("deletedAt").isNull();                 // null 체크 — Spring Data MongoDB 4.x+ (Boot 3.2+)
```

주요 비교 메서드는 다음과 같다.

| 메서드 | MongoDB 연산자 | 의미 |
|--------|---------------|------|
| `is` / `ne` | `$eq` / `$ne` | 같음 / 같지 않음 |
| `gt` / `gte` / `lt` / `lte` | `$gt` / `$gte` / `$lt` / `$lte` | 비교 연산 |
| `in` / `nin` | `$in` / `$nin` | 포함 / 미포함 |
| `regex(pattern)` | `$regex` | 정규표현식 매칭 |
| `exists(boolean)` | `$exists` | 필드 존재 여부 |

### 8.2.2 복잡한 조건 조합 (and/or/in/regex)

실무에서는 사용자의 검색 조건이 복합적이어서 여러 논리 연산자를 조합해야 한다. 다음 예제들이 자주 나타나는 패턴들이다.

```java
// AND 조건 — 체이닝
Query query = Query.query(
    Criteria.where("category").is("electronics")
        .and("price").gte(10000).and("stock").gt(0)
);

// OR 조건
Query query = Query.query(
    new Criteria().orOperator(
        Criteria.where("category").is("electronics"),
        Criteria.where("category").is("books")
    )
);

// AND + OR 혼합
Query query = Query.query(
    new Criteria().orOperator(
        new Criteria().andOperator(
            Criteria.where("category").is("electronics"),
            Criteria.where("price").gte(10000)),
        new Criteria().andOperator(
            Criteria.where("category").is("books"),
            Criteria.where("price").gte(5000))
    )
);

// in, regex, elemMatch
Criteria.where("category").in("electronics", "books", "clothing");
Criteria.where("name").regex("갤럭시", "i");  // 대소문자 무시
Criteria.where("tags").elemMatch(
    Criteria.where("name").is("sale").and("active").is(true)
);
```

### 8.2.3 정렬, 페이징, Projection

검색 결과를 정렬하고 페이징하는 것은 기본이다. 그리고 때론 모든 필드가 필요한 게 아니라 특정 필드만 가져오면 되는 경우도 있는데, 이때 Projection을 사용하면 네트워크 트래픽과 메모리 사용량을 줄일 수 있다.

```java
// 정렬 + 페이징
public Flux<Product> findWithPaging(String category, int page, int size) {
    Query query = Query.query(Criteria.where("category").is(category))
        .with(Sort.by(Sort.Direction.DESC, "createdAt"))
        .skip((long) page * size)
        .limit(size);
    return mongoTemplate.find(query, Product.class);
}

// 전체 건수 조회 (페이징 UI용)
public Mono<Long> countByCategory(String category) {
    Query query = Query.query(Criteria.where("category").is(category));
    return mongoTemplate.count(query, Product.class);
}

// Projection — 필요한 필드만 선택
public Flux<ProductSummary> findSummaries() {
    Query query = new Query();
    query.fields().include("name").include("price").include("category");
    return mongoTemplate.find(query, ProductSummary.class, "products");
}
```

### 8.2.4 동적 쿼리 구성

이 부분이 정말 중요하다. 실무에서는 사용자가 모든 필터를 입력하지 않는다. 카테고리만 선택할 수도 있고, 가격 범위만 선택할 수도 있고, 검색어만 입력할 수도 있다. 따라서 쿼리를 동적으로 구성해야 한다.

```java
@Service
@RequiredArgsConstructor
public class ProductSearchService {

    private final ReactiveMongoTemplate mongoTemplate;

    public Flux<Product> search(ProductSearchCriteria sc) {
        Query query = new Query();

        if (sc.getCategory() != null) {
            query.addCriteria(Criteria.where("category").is(sc.getCategory()));
        }
        if (sc.getMinPrice() != null || sc.getMaxPrice() != null) {
            Criteria price = Criteria.where("price");
            if (sc.getMinPrice() != null) price = price.gte(sc.getMinPrice());
            if (sc.getMaxPrice() != null) price = price.lte(sc.getMaxPrice());
            query.addCriteria(price);
        }
        if (sc.getKeyword() != null) {
            query.addCriteria(Criteria.where("name").regex(sc.getKeyword(), "i"));
        }
        if (Boolean.TRUE.equals(sc.getInStockOnly())) {
            query.addCriteria(Criteria.where("stock").gt(0));
        }

        query.with(Sort.by(
            Sort.Direction.fromString(
                sc.getSortDirection() != null ? sc.getSortDirection() : "DESC"),
            sc.getSortBy() != null ? sc.getSortBy() : "createdAt"
        ));
        query.skip((long) sc.getPage() * sc.getSize()).limit(sc.getSize());

        return mongoTemplate.find(query, Product.class);
    }
}
```

```java
@Data
@Builder
public class ProductSearchCriteria {
    private String category;
    private BigDecimal minPrice;
    private BigDecimal maxPrice;
    private String keyword;
    private Boolean inStockOnly;
    private String sortBy;
    private String sortDirection;
    @Builder.Default private int page = 0;
    @Builder.Default private int size = 20;
}
```

---

## 8.3 Aggregation Pipeline 사용

### 8.3.1 Aggregation Pipeline 개념

이제 정말 흥미로운 부분이다. Aggregation Pipeline은 MongoDB의 강력한 기능으로, 도큐먼트들을 여러 단계를 거쳐 변환하고 집계한다. 마치 데이터가 파이프라인을 따라 흐르면서 각 단계에서 필터링, 그룹핑, 정렬 등을 거치는 것 같다고 생각하면 된다. Spring Data MongoDB는 이 과정을 자바로 깔끔하게 표현할 수 있게 `Aggregation` 클래스를 제공한다.

| 단계 | MongoDB 연산자 | Spring Data 메서드 | 설명 |
|------|---------------|-------------------|------|
| Match | `$match` | `Aggregation.match()` | 도큐먼트 필터링 |
| Group | `$group` | `Aggregation.group()` | 그룹별 집계 |
| Sort | `$sort` | `Aggregation.sort()` | 결과 정렬 |
| Project | `$project` | `Aggregation.project()` | 필드 선택/변환 |
| Unwind | `$unwind` | `Aggregation.unwind()` | 배열 분해 |
| Lookup | `$lookup` | `Aggregation.lookup()` | 컬렉션 조인 |

### 8.3.2 기본 집계: 카테고리별 통계

가장 단순하면서도 유용한 예제부터 보자. 활성 상태의 상품들을 카테고리별로 그룹핑해서 통계를 낸다.

```java
public Flux<CategoryStats> getCategoryStats() {
    Aggregation aggregation = Aggregation.newAggregation(
        Aggregation.match(Criteria.where("active").is(true)),
        Aggregation.group("category")
            .count().as("productCount")
            .avg("price").as("avgPrice")
            .min("price").as("minPrice")
            .max("price").as("maxPrice")
            .sum("stock").as("totalStock"),
        Aggregation.sort(Sort.Direction.DESC, "productCount"),
        Aggregation.project()
            .and("_id").as("category")
            .andInclude("productCount", "avgPrice", "minPrice", "maxPrice", "totalStock")
    );
    return mongoTemplate.aggregate(aggregation, "products", CategoryStats.class);
}
```

```java
@Data
public class CategoryStats {
    private String category;
    private long productCount;
    private double avgPrice;
    private double minPrice;
    private double maxPrice;
    private long totalStock;
}
```

### 8.3.3 TypedAggregation

작은 팁이지만 실무에서는 꽤 유용하다. `TypedAggregation`을 사용하면 도메인 클래스를 첫 번째 인자로 전달해서 컬렉션 이름을 자동으로 추론할 수 있다. `Aggregation.newAggregation(Product.class, ...)`처럼 쓰면 되고, `aggregate()` 호출할 때 컬렉션 이름을 명시하지 않아도 된다는 뜻이다. 코드가 조금 더 깔끔해진다.

### 8.3.4 Unwind와 Lookup

두 가지 고급 스테이지가 있다. **Unwind**는 배열 필드를 개별 도큐먼트로 분해해서, 배열의 각 요소에 대해 별도의 행이 생기도록 한다. **Lookup**은 SQL의 JOIN처럼 다른 컬렉션과 조인하는 역할을 한다.

```java
// 태그별 상품 수 집계 (Unwind)
public Flux<TagStats> getTagStats() {
    Aggregation aggregation = Aggregation.newAggregation(
        Aggregation.unwind("tags"),
        Aggregation.group("tags").count().as("count").avg("price").as("avgPrice"),
        Aggregation.sort(Sort.Direction.DESC, "count"),
        Aggregation.limit(10)
    );
    return mongoTemplate.aggregate(aggregation, "products", TagStats.class);
}

// 주문 + 사용자 조인 (Lookup)
public Flux<OrderWithUser> getOrdersWithUserInfo() {
    Aggregation aggregation = Aggregation.newAggregation(
        Aggregation.lookup("users", "userId", "_id", "userInfo"),
        Aggregation.unwind("userInfo"),
        Aggregation.project()
            .andInclude("orderDate", "totalAmount", "status")
            .and("userInfo.name").as("userName")
            .and("userInfo.email").as("userEmail")
    );
    return mongoTemplate.aggregate(aggregation, "orders", OrderWithUser.class);
}
```

### 8.3.5 실전 통계 API: 일별 매출 집계

이제 실제로 대시보드에 쓸 수 있는 통계를 만들어보자. 일정 기간 동안 완료된 주문들의 일별 매출, 주문 건수, 평균 주문액을 조회한다.

```java
@Service
@RequiredArgsConstructor
public class SalesStatisticsService {

    private final ReactiveMongoTemplate mongoTemplate;

    public Flux<DailySales> getDailySales(LocalDateTime from, LocalDateTime to) {
        Aggregation aggregation = Aggregation.newAggregation(
            Aggregation.match(
                Criteria.where("orderDate").gte(from).lte(to)
                    .and("status").is("COMPLETED")),
            Aggregation.project()
                .andExpression("dateToString('%Y-%m-%d', orderDate)").as("date")
                .andInclude("totalAmount"),
            Aggregation.group("date")
                .sum("totalAmount").as("totalSales")
                .count().as("orderCount")
                .avg("totalAmount").as("avgOrderAmount"),
            Aggregation.sort(Sort.Direction.ASC, "_id"),
            Aggregation.project()
                .and("_id").as("date")
                .andInclude("totalSales", "orderCount", "avgOrderAmount")
        );
        return mongoTemplate.aggregate(aggregation, "orders", DailySales.class);
    }
}
```

```java
@RestController
@RequestMapping("/api/statistics")
@RequiredArgsConstructor
public class StatisticsController {

    private final SalesStatisticsService salesStatisticsService;

    @GetMapping("/daily-sales")
    public Flux<DailySales> getDailySales(
            @RequestParam @DateTimeFormat(iso = DateTimeFormat.ISO.DATE_TIME) LocalDateTime from,
            @RequestParam @DateTimeFormat(iso = DateTimeFormat.ISO.DATE_TIME) LocalDateTime to) {
        return salesStatisticsService.getDailySales(from, to);
    }
}
```

---

## 8.4 변경 스트림(Change Streams) 활용

### 8.4.1 Change Streams 개념

MongoDB의 Change Streams라는 기능이 있는데, 이걸 쓰면 컬렉션의 모든 데이터 변경(삽입, 수정, 삭제)을 실시간으로 감시할 수 있다. 내부적으로는 MongoDB의 oplog를 기반으로 동작한다. 주의할 점은 **Replica Set 또는 Sharded Cluster 환경에서만 사용 가능**하다는 것인데, 로컬 개발 환경에서도 Docker로 단일 노드 Replica Set을 구성하면 테스트할 수 있다. 실시간 알림, 이벤트 발행, 데이터 동기화, 캐시 무효화 같은 작업에 유용하다.

### 8.4.2 ReactiveMongoTemplate으로 Change Streams 구독

`ReactiveMongoTemplate`의 `changeStream()` 메서드를 사용하면 특정 컬렉션의 변경을 Flux로 수신할 수 있다. 여러 필터를 조합해서 원하는 이벤트만 감시할 수 있다.

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class OrderChangeStreamService {

    private final ReactiveMongoTemplate mongoTemplate;

    // INSERT 이벤트 실시간 감시
    public Flux<ChangeStreamEvent<Order>> watchNewOrders() {
        return mongoTemplate.changeStream("orders",
                ChangeStreamOptions.builder()
                    .filter(Aggregation.newAggregation(
                        Aggregation.match(
                            Criteria.where("operationType").is("insert"))))
                    .build(),
                Order.class)
            .doOnNext(event -> log.info("새 주문 감지: orderId={}",
                event.getBody().getId()));
    }

    // UPDATE 이벤트 감시 (전체 도큐먼트 수신)
    public Flux<ChangeStreamEvent<Order>> watchOrderStatusChanges() {
        return mongoTemplate.changeStream("orders",
                ChangeStreamOptions.builder()
                    .filter(Aggregation.newAggregation(
                        Aggregation.match(
                            Criteria.where("operationType").is("update")
                                .and("updateDescription.updatedFields.status").exists(true))))
                    .returnFullDocumentOnUpdate()
                    .build(),
                Order.class);
    }
}
```

한 가지 중요한 옵션이 `returnFullDocumentOnUpdate()`인데, 이걸 호출하면 UPDATE 이벤트가 발생했을 때 변경된 필드만 받는 대신 전체 도큐먼트를 받을 수 있다. 상황에 따라 필요한 쪽을 선택해서 사용하면 된다.

### 8.4.3 Change Streams + SSE 연동

Change Streams로 감시한 이벤트를 Server-Sent Events(SSE)로 클라이언트에게 실시간으로 푸시할 수 있다. 이렇게 하면 웹 클라이언트가 새로운 주문, 상태 변경 같은 이벤트를 즉시 받을 수 있다.

```java
@RestController
@RequestMapping("/api/notifications")
@RequiredArgsConstructor
public class NotificationController {

    private final OrderChangeStreamService changeStreamService;

    @GetMapping(value = "/orders", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<ServerSentEvent<Order>> streamNewOrders() {
        return changeStreamService.watchNewOrders()
            .map(event -> ServerSentEvent.<Order>builder()
                .id(event.getResumeToken().toJson())
                .event("new-order")
                .data(event.getBody())
                .build());
    }
}
```

### 8.4.4 Resume Token을 이용한 재연결

실시간 시스템의 가장 까다로운 부분은 네트워크가 끊어졌을 때 처리다. Change Streams는 이런 상황에 대비해 `resume token`이라는 것을 제공한다. 이 토큰을 저장해두면 연결이 끊어진 후에도 마지막 이벤트부터 이어서 수신할 수 있다. 아주 유용한 기능이다.

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class ResilientChangeStreamService {

    private final ReactiveMongoTemplate mongoTemplate;
    private final ResumeTokenStore tokenStore;

    public Flux<ChangeStreamEvent<Order>> watchWithResume(String streamId) {
        return tokenStore.getLastToken(streamId)
            .map(token -> ChangeStreamOptions.builder().resumeAfter(token).build())
            .defaultIfEmpty(ChangeStreamOptions.empty())
            .flatMapMany(options -> mongoTemplate.changeStream("orders", options, Order.class))
            .doOnNext(event ->
                tokenStore.saveToken(streamId, event.getResumeToken()).subscribe())
            .retryWhen(Retry.backoff(Long.MAX_VALUE, Duration.ofSeconds(1))
                .maxBackoff(Duration.ofMinutes(1))
                .doBeforeRetry(signal ->
                    log.warn("Change Stream 재연결 시도: attempt={}",
                        signal.totalRetries())));
    }
}
```

`ResumeTokenStore` 컴포넌트는 resume token을 MongoDB에 저장하고 조회하는 역할을 한다. 보통 `upsert`를 활용해서 구현한다. 이벤트를 처리할 때마다 토큰을 저장해두면 애플리케이션이 재시작되더라도 유실 없이 그 다음부터의 이벤트를 이어서 수신할 수 있다. 필자의 경험상 이런 안정성 기능은 프로덕션 환경에서 정말 중요하다.

---

## 8.5 트랜잭션 처리 (ReactiveMongoTransactionManager)

### 8.5.1 MongoDB 트랜잭션의 전제 조건

MongoDB의 트랜잭션은 꽤 최근에 지원되기 시작했고, 중요한 제약이 하나 있다. **Replica Set 환경에서만 사용할 수 있다**는 것이다. 다행히 Docker Compose로 단일 노드 Replica Set을 구성할 수 있어서 로컬 개발 환경에서도 충분히 테스트할 수 있다.

```yaml
# docker-compose.yml
services:
  mongodb:
    image: mongo:7.0
    ports:
      - "27017:27017"
    command: ["--replSet", "rs0", "--bind_ip_all"]
    healthcheck:
      test: echo "try { rs.status() } catch (err) { rs.initiate() }" | mongosh
      interval: 5s
      timeout: 30s
      retries: 5
```

### 8.5.2 ReactiveMongoTransactionManager 설정

```java
@Configuration
public class MongoTransactionConfig {

    @Bean
    public ReactiveMongoTransactionManager transactionManager(
            ReactiveMongoDatabaseFactory dbFactory) {
        return new ReactiveMongoTransactionManager(dbFactory);
    }
}
```

### 8.5.3 @Transactional 어노테이션 사용

가장 간단한 방법은 서비스 메서드에 `@Transactional`을 붙이는 것이다. Spring이 자동으로 트랜잭션 경계를 관리해주고, 예외가 발생하면 모든 변경사항을 자동으로 롤백한다.

```java
@Service
@RequiredArgsConstructor
public class OrderService {

    private final ReactiveMongoTemplate mongoTemplate;
    private final ProductService productService;

    @Transactional
    public Mono<Order> createOrder(OrderRequest request) {
        return Flux.fromIterable(request.getItems())
            .flatMap(item ->
                productService.decrementStock(item.getProductId(), item.getQuantity())
                    .switchIfEmpty(Mono.error(new InsufficientStockException(
                        "재고 부족: productId=" + item.getProductId()))))
            .collectList()
            .flatMap(products -> {
                Order order = Order.builder()
                    .userId(request.getUserId())
                    .items(request.getItems())
                    .totalAmount(calculateTotal(request.getItems(), products))
                    .status("CREATED")
                    .orderDate(LocalDateTime.now())
                    .build();
                return mongoTemplate.insert(order);
            });
    }
}
```

### 8.5.4 TransactionalOperator 프로그래밍 방식

선언적 방식 외에도 프로그래밍 방식으로 트랜잭션 경계를 세밀하게 제어할 수 있다. `TransactionalOperator`를 사용하면 더 유연해진다. 예를 들어 특정 조건에서만 트랜잭션을 적용하거나, 여러 개의 독립적인 트랜잭션을 순서대로 실행할 때 유용하다.

```java
@Service
@RequiredArgsConstructor
public class TransferService {

    private final ReactiveMongoTemplate mongoTemplate;
    private final TransactionalOperator transactionalOperator;

    public Mono<TransferResult> transferPoints(
            String fromUserId, String toUserId, int amount) {

        Mono<TransferResult> transferMono = deductPoints(fromUserId, amount)
            .then(addPoints(toUserId, amount))
            .then(createTransferLog(fromUserId, toUserId, amount))
            .map(log -> new TransferResult("SUCCESS", log.getId()));

        return transactionalOperator.transactional(transferMono);
    }

    private Mono<UpdateResult> deductPoints(String userId, int amount) {
        Query query = Query.query(
            Criteria.where("id").is(userId).and("points").gte(amount));
        Update update = new Update().inc("points", -amount);
        return mongoTemplate.updateFirst(query, update, User.class)
            .flatMap(result -> result.getModifiedCount() == 0
                ? Mono.error(new InsufficientPointsException("포인트 부족"))
                : Mono.just(result));
    }

    private Mono<UpdateResult> addPoints(String userId, int amount) {
        Query query = Query.query(Criteria.where("id").is(userId));
        return mongoTemplate.updateFirst(query, new Update().inc("points", amount), User.class);
    }

    private Mono<TransferLog> createTransferLog(
            String fromUserId, String toUserId, int amount) {
        return mongoTemplate.insert(TransferLog.builder()
            .fromUserId(fromUserId).toUserId(toUserId)
            .amount(amount).transferredAt(LocalDateTime.now()).build());
    }
}
```

### 8.5.5 @Transactional vs TransactionalOperator 선택 기준

| 비교 항목 | @Transactional | TransactionalOperator |
|-----------|---------------|----------------------|
| **사용 방식** | 선언적 (어노테이션) | 프로그래밍 방식 |
| **적합한 곳** | 서비스 계층 메서드 단위 | 함수형 엔드포인트, 세밀한 제어 |
| **트랜잭션 범위** | 메서드 전체 | `transactional()` 호출 범위 |
| **유연성** | 제한적 | 높음 (조건부 트랜잭션 등) |

---

## 8.6 인덱스 관리와 쿼리 성능 최적화

### 8.6.1 @Indexed 어노테이션

이제 성능 최적화 부분으로 넘어가자. 인덱스 없이 운영하는 MongoDB 시스템은 결국 느려진다. Spring Data MongoDB는 `@Indexed` 어노테이션으로 단순하게 인덱스를 선언할 수 있게 해준다.

```java
@Document(collection = "products")
@Data @Builder @NoArgsConstructor @AllArgsConstructor
public class Product {

    @Id
    private String id;
    private String name;

    @Indexed
    private String category;

    private BigDecimal price;

    @Indexed(unique = true)
    private String sku;

    @Indexed(direction = IndexDirection.DESCENDING)
    private LocalDateTime createdAt;

    private int stock;
    private boolean active;
    private List<String> tags;
}
```

> **주의**: Spring Boot 3.x부터 `auto-index-creation`이 기본값 `false`다. `@Indexed`가 동작하려면 명시적으로 활성화해야 한다.

```yaml
spring:
  data:
    mongodb:
      auto-index-creation: true
```

### 8.6.2 @CompoundIndex 복합 인덱스

실무에서는 단일 필드 인덱스만으로는 부족하다. 여러 필드를 조합해서 인덱스를 만들어야 하는 경우가 많은데, 이때는 `@CompoundIndex`를 사용한다.

```java
@Document(collection = "products")
@CompoundIndex(name = "category_price_idx", def = "{'category': 1, 'price': -1}")
@CompoundIndex(name = "category_active_created_idx",
               def = "{'category': 1, 'active': 1, 'createdAt': -1}")
public class Product { /* ... */ }
```

복합 인덱스의 필드 순서는 정말 중요한데, **ESR (Equality, Sort, Range) 규칙**을 따르면 최적화된다.

1. **Equality**: 등호(`=`) 조건 필드를 먼저 배치
2. **Sort**: 정렬 필드를 다음에 배치
3. **Range**: 범위 조건(`>=`, `<=`) 필드를 마지막에 배치

```java
// 쿼리: category = ? AND active = ?, 정렬: createdAt DESC, 조건: price >= ?
// 최적 인덱스: { category: 1, active: 1, createdAt: -1, price: 1 }
@CompoundIndex(name = "optimized_search_idx",
               def = "{'category': 1, 'active': 1, 'createdAt': -1, 'price': 1}")
```

### 8.6.3 TTL 인덱스

TTL 인덱스는 흥미로운 기능이다. 지정된 시간이 지나면 도큐먼트를 자동으로 삭제해주는데, 세션 데이터, 임시 토큰, 로그 같은 일시적 데이터를 관리할 때 정말 유용하다. 수동으로 정리 작업을 구현할 필요가 없어진다.

```java
@Document(collection = "sessions")
@Data @Builder @NoArgsConstructor @AllArgsConstructor
public class Session {

    @Id
    private String id;
    private String userId;
    private String token;

    @Indexed(expireAfterSeconds = 3600)  // 1시간 후 자동 삭제
    private LocalDateTime createdAt;
}
```

대상 필드는 반드시 `Date` 또는 `LocalDateTime` 타입이어야 한다. MongoDB 백그라운드 태스크가 60초 간격으로 만료 도큐먼트를 삭제하므로, 실제 삭제 시점은 약간의 지연이 있을 수 있다.

### 8.6.4 프로그래밍 방식 인덱스 생성과 Partial Index

어노테이션으로 인덱스를 선언하는 것도 좋지만, 때론 애플리케이션 시작 시에 동적으로 인덱스를 생성해야 할 수도 있다. `ReactiveMongoTemplate`의 `indexOps()`를 사용하면 이게 가능하다. 또한 **Partial Index**라는 개념도 있는데, 특정 조건을 만족하는 도큐먼트에만 인덱스를 적용하는 기법이다. 이렇게 하면 저장 공간도 절약하고 쓰기 성능도 개선된다.

```java
@Component
@RequiredArgsConstructor
@Slf4j
public class IndexInitializer implements ApplicationRunner {

    private final ReactiveMongoTemplate mongoTemplate;

    @Override
    public void run(ApplicationArguments args) {
        ReactiveIndexOperations indexOps = mongoTemplate.indexOps(Product.class);
        Index partialIndex = new Index()
            .on("price", IndexDirection.ASCENDING)
            .named("active_products_price_idx")
            .partial(PartialIndexFilter.of(Criteria.where("active").is(true)));
        indexOps.ensureIndex(partialIndex)
            .doOnSuccess(name -> log.info("인덱스 생성 완료: {}", name))
            .subscribe();
    }
}
```

### 8.6.5 explain()으로 쿼리 실행 계획 분석

인덱스를 만들었다고 해서 항상 인덱스가 사용되는 건 아니다. 쿼리가 정말로 인덱스를 활용하고 있는지 확인하려면 `explain()`으로 실행 계획을 분석해야 한다. `ReactiveMongoTemplate`에서 네이티브 컬렉션을 가져와 `explain()`을 호출하면 실행 계획을 얻을 수 있다. 결과에서 `queryPlanner.winningPlan.stage`가 `IXSCAN`(인덱스 스캔)이면 좋은 것이고, `COLLSCAN`(컬렉션 풀 스캔)이라면 인덱스를 다시 설계해야 한다는 뜻이다. 또한 `totalDocsExamined`와 `nReturned`가 비슷할수록 인덱스가 잘 설계된 것이다.

### 8.6.6 인덱스 설계 실무 가이드라인

마지막으로 실제 프로덕션에서 적용할 수 있는 가이드라인을 정리하면:

1. **가장 자주 실행되는 쿼리부터 우선으로 인덱스를 설계한다.** 모든 필드에 인덱스를 걸 필요는 없다.
2. **복합 인덱스는 ESR 규칙을 따른다.** Equality, Sort, Range 순서로 필드를 배치해야 효율적이다.
3. **인덱스는 쓰기 성능에 영향을 미친다.** 매번 INSERT/UPDATE할 때마다 인덱스도 갱신해야 하므로 불필요한 인덱스는 제거하자.
4. **Covered Query를 활용한다.** 필요한 모든 필드가 인덱스에 포함되면 실제 도큐먼트를 읽지 않고 결과를 반환할 수 있다.
5. **Partial Index로 인덱스 크기를 줄인다.** 활성 데이터만 인덱싱하면 저장 공간과 성능을 모두 개선할 수 있다.

---

## 요약

| 주제 | 핵심 내용 |
|------|----------|
| **ReactiveMongoTemplate** | `Query`/`Update` 객체로 세밀한 CRUD, 부분 업데이트, Upsert 수행 |
| **Criteria API** | 동적 쿼리 조합, and/or/in/regex 조건, 정렬/페이징/Projection |
| **Aggregation Pipeline** | match/group/sort/project/unwind/lookup으로 복잡한 집계와 통계 API 구현 |
| **Change Streams** | 컬렉션 변경을 실시간 감시, resume token으로 재연결 시 이벤트 유실 방지 |
| **트랜잭션** | Replica Set 필수, `@Transactional` 또는 `TransactionalOperator`로 원자적 연산 보장 |
| **인덱스 최적화** | `@Indexed`, `@CompoundIndex`, TTL 인덱스, ESR 규칙, explain 분석으로 쿼리 성능 개선 |

다음 장에서는 데이터 검증과 예외 처리로 넘어간다. Bean Validation을 활용한 입력값 검증, 커스텀 Validator 작성, 글로벌 예외 처리 구조, 클라이언트 친화적인 에러 응답 표준화 등을 살펴볼 예정이다.
