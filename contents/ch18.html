<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Chapter 18. 모니터링과 관측 가능성 | Spring Boot + WebFlux + JPA (MongoDB)</title>
  <link rel="stylesheet" href="../css/style.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
</head>
<body>
  <header class="site-header">
    <h1><a href="../index.html">Spring Boot + WebFlux + JPA (MongoDB)</a></h1>
  </header>
    <nav class="nav-bar">
    <a href="ch17.html">&larr; Chapter 17. 문서화와 API 관리</a>
    <a href="../index.html">목차</a>
    <a href="ch19.html">Chapter 19. 성능 최적화 &rarr;</a>
  </nav>
  <div class="wrapper">
    <main class="content">
      <h1 id="chapter-18">Chapter 18. 모니터링과 관측 가능성</h1>
<p>운영 환경에서 리액티브 애플리케이션을 안정적으로 관리하려면 세 가지 관측 가능성(Observability) 축이 필요하다. <strong>메트릭(Metrics)</strong>, <strong>트레이스(Traces)</strong>, <strong>로그(Logs)</strong>다. 전통적인 서블릿 기반 애플리케이션과 달리, WebFlux 애플리케이션은 하나의 요청이 여러 스레드를 넘나들며 처리되므로 <code>ThreadLocal</code> 기반의 기존 모니터링 방식만으로는 한계가 있다. 이번 장에서는 Spring Boot Actuator를 기반으로 메트릭을 노출하고, Micrometer와 Prometheus로 수집하며, Grafana로 시각화하는 전체 파이프라인을 구성한다. 나아가 Reactor 스트림 내부의 메트릭 수집, 분산 추적(Zipkin/Jaeger), 그리고 리액티브 환경에서의 구조화된 로깅까지 실전에서 필요한 관측 가능성 전략을 종합적으로 다룬다.</p>
<hr>
<h2 id="181-spring-boot-actuator">18.1 Spring Boot Actuator 설정</h2>
<h3 id="1811-actuator">18.1.1 Actuator 소개와 의존성</h3>
<p>Spring Boot Actuator는 애플리케이션의 상태, 메트릭, 환경 정보 등을 HTTP 엔드포인트로 노출하는 운영 도구 모듈이다. WebFlux 환경에서도 동일하게 동작하며, 리액티브 기반의 Health Indicator를 제공한다.</p>
<pre class="highlight"><code class="language-groovy">dependencies {
    implementation 'org.springframework.boot:spring-boot-starter-webflux'
    implementation 'org.springframework.boot:spring-boot-starter-data-mongodb-reactive'
    implementation 'org.springframework.boot:spring-boot-starter-actuator'
}</code></pre>
<h3 id="1812">18.1.2 엔드포인트 활성화와 노출 설정</h3>
<p>기본적으로 Actuator는 대부분의 엔드포인트를 활성화하지만, HTTP로 노출되는 것은 <code>health</code>뿐이다. 운영에 필요한 엔드포인트를 선택적으로 노출한다.</p>
<pre class="highlight"><code class="language-yaml"># application.yml
management:
  endpoints:
    web:
      exposure:
        include: health, info, metrics, prometheus, env, loggers
      base-path: /actuator
  endpoint:
    health:
      show-details: when_authorized
      show-components: when_authorized
    info:
      enabled: true
  info:
    env:
      enabled: true
    java:
      enabled: true
    os:
      enabled: true</code></pre>
<p>주요 엔드포인트는 다음과 같다.</p>
<table>
<thead>
<tr>
<th>엔드포인트</th>
<th>경로</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>health</strong></td>
<td><code>/actuator/health</code></td>
<td>애플리케이션 및 의존 서비스 상태</td>
</tr>
<tr>
<td><strong>info</strong></td>
<td><code>/actuator/info</code></td>
<td>애플리케이션 정보 (버전, Git 커밋 등)</td>
</tr>
<tr>
<td><strong>metrics</strong></td>
<td><code>/actuator/metrics</code></td>
<td>Micrometer 기반 메트릭 목록</td>
</tr>
<tr>
<td><strong>prometheus</strong></td>
<td><code>/actuator/prometheus</code></td>
<td>Prometheus 형식의 메트릭</td>
</tr>
<tr>
<td><strong>loggers</strong></td>
<td><code>/actuator/loggers</code></td>
<td>런타임 로그 레벨 변경</td>
</tr>
</tbody>
</table>
<h3 id="1813-health-indicator">18.1.3 커스텀 Health Indicator</h3>
<p>MongoDB Reactive 스타터를 사용하면 <code>ReactiveMongoHealthIndicator</code>가 자동 등록된다. 자동 감지되지 않는 외부 서비스의 상태를 확인하려면 <code>ReactiveHealthIndicator</code>를 직접 구현한다.</p>
<pre class="highlight"><code class="language-java">@Component
public class ExternalPaymentServiceHealthIndicator
        implements ReactiveHealthIndicator {

    private final WebClient paymentClient;

    public ExternalPaymentServiceHealthIndicator(
            @Qualifier("paymentServiceClient") WebClient paymentClient) {
        this.paymentClient = paymentClient;
    }

    @Override
    public Mono&lt;Health&gt; health() {
        return paymentClient.get()
            .uri("/health")
            .retrieve()
            .bodyToMono(String.class)
            .map(response -&gt; Health.up()
                .withDetail("service", "payment-api").build())
            .onErrorResume(ex -&gt; Mono.just(Health.down()
                .withDetail("service", "payment-api")
                .withDetail("error", ex.getMessage()).build()))
            .timeout(Duration.ofSeconds(3),
                Mono.just(Health.down()
                    .withDetail("error", "Health check timed out").build()));
    }
}</code></pre>
<h3 id="1814-actuator">18.1.4 Actuator 보안 설정</h3>
<p>Actuator 엔드포인트에는 민감한 정보가 포함될 수 있으므로, Spring Security WebFlux와 연동하여 접근을 제한해야 한다.</p>
<pre class="highlight"><code class="language-java">@Configuration
@EnableWebFluxSecurity
public class ActuatorSecurityConfig {

    @Bean
    public SecurityWebFilterChain securityWebFilterChain(
            ServerHttpSecurity http) {
        return http
            .authorizeExchange(exchanges -&gt; exchanges
                .pathMatchers("/actuator/health", "/actuator/info").permitAll()
                .pathMatchers("/actuator/prometheus").hasRole("MONITORING")
                .pathMatchers("/actuator/**").hasRole("ADMIN")
                .pathMatchers("/api/**").authenticated()
                .anyExchange().permitAll()
            )
            .httpBasic(Customizer.withDefaults())
            .csrf(csrf -&gt; csrf.disable())
            .build();
    }
}</code></pre>
<p>운영 환경에서는 Actuator 포트를 별도로 분리하는 것도 권장된다.</p>
<pre class="highlight"><code class="language-yaml"># application-prod.yml
management:
  server:
    port: 9090
  endpoints:
    web:
      exposure:
        include: health, prometheus</code></pre>
<p>이렇게 하면 애플리케이션은 8080 포트에서, Actuator는 9090 포트에서 서비스되므로 방화벽 규칙으로 외부 접근을 차단할 수 있다.</p>
<hr>
<h2 id="182-micrometer-prometheus">18.2 Micrometer와 Prometheus 연동</h2>
<h3 id="1821-micrometer">18.2.1 Micrometer 소개</h3>
<p>Micrometer는 JVM 기반 애플리케이션을 위한 <strong>벤더 중립적 메트릭 파사드</strong>다. SLF4J가 로깅 구현체를 추상화하듯, Micrometer는 Prometheus, Datadog, CloudWatch 등 메트릭 수집 구현체를 추상화한다. Spring Boot Actuator는 내부적으로 Micrometer를 사용한다.</p>
<pre class="highlight"><code class="language-groovy">dependencies {
    implementation 'org.springframework.boot:spring-boot-starter-actuator'
    implementation 'io.micrometer:micrometer-registry-prometheus'
}</code></pre>
<p>위 의존성을 추가하면 <code>/actuator/prometheus</code> 엔드포인트가 자동으로 활성화된다.</p>
<h3 id="1822">18.2.2 자동 수집 메트릭</h3>
<p>Spring Boot와 Micrometer는 별도 코드 없이도 다양한 메트릭을 자동 수집한다.</p>
<table>
<thead>
<tr>
<th>카테고리</th>
<th>메트릭 예시</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>JVM</strong></td>
<td><code>jvm_memory_used_bytes</code></td>
<td>힙/논힙 메모리 사용량</td>
</tr>
<tr>
<td><strong>JVM</strong></td>
<td><code>jvm_gc_pause_seconds</code></td>
<td>GC 일시 정지 시간</td>
</tr>
<tr>
<td><strong>HTTP</strong></td>
<td><code>http_server_requests_seconds</code></td>
<td>HTTP 요청 처리 시간 (uri, method, status별)</td>
</tr>
<tr>
<td><strong>MongoDB</strong></td>
<td><code>mongodb_driver_pool_size</code></td>
<td>MongoDB 커넥션 풀 크기</td>
</tr>
<tr>
<td><strong>MongoDB</strong></td>
<td><code>mongodb_driver_commands_seconds</code></td>
<td>MongoDB 명령 실행 시간</td>
</tr>
<tr>
<td><strong>System</strong></td>
<td><code>system_cpu_usage</code></td>
<td>시스템 CPU 사용률</td>
</tr>
</tbody>
</table>
<h3 id="1823-counter">18.2.3 커스텀 메트릭 -- Counter</h3>
<p><code>Counter</code>는 단조 증가하는 값을 추적한다. 주문 건수, 에러 발생 횟수 등을 기록하는 데 적합하다.</p>
<pre class="highlight"><code class="language-java">@Service
@RequiredArgsConstructor
public class OrderService {

    private final OrderRepository orderRepository;
    private final MeterRegistry meterRegistry;

    public Mono&lt;Order&gt; createOrder(OrderRequest request) {
        return orderRepository.save(Order.from(request))
            .doOnSuccess(order -&gt;
                Counter.builder("orders.created")
                    .description("총 생성된 주문 수")
                    .tag("category", order.getCategory())
                    .tag("payment_method", order.getPaymentMethod())
                    .register(meterRegistry)
                    .increment())
            .doOnError(ex -&gt;
                Counter.builder("orders.failed")
                    .description("주문 실패 수")
                    .tag("error_type", ex.getClass().getSimpleName())
                    .register(meterRegistry)
                    .increment());
    }
}</code></pre>
<h3 id="1824-gauge">18.2.4 커스텀 메트릭 -- Gauge</h3>
<p><code>Gauge</code>는 현재 값을 나타낸다. 대기열 크기, 활성 연결 수 등 증감이 모두 가능한 값에 사용한다.</p>
<pre class="highlight"><code class="language-java">@Component
public class QueueMetrics {

    private final AtomicInteger pendingTaskCount = new AtomicInteger(0);

    public QueueMetrics(MeterRegistry meterRegistry) {
        Gauge.builder("tasks.pending", pendingTaskCount, AtomicInteger::get)
            .description("처리 대기 중인 작업 수")
            .register(meterRegistry);
    }

    public void taskAdded() { pendingTaskCount.incrementAndGet(); }
    public void taskCompleted() { pendingTaskCount.decrementAndGet(); }
}</code></pre>
<h3 id="1825-timer">18.2.5 커스텀 메트릭 -- Timer</h3>
<p><code>Timer</code>는 작업의 소요 시간과 호출 횟수를 함께 기록한다. 성능 분석에 필수적이다.</p>
<pre class="highlight"><code class="language-java">@Service
@RequiredArgsConstructor
public class ProductSearchService {

    private final ReactiveMongoTemplate mongoTemplate;
    private final MeterRegistry meterRegistry;

    public Flux&lt;Product&gt; search(String keyword) {
        Timer.Sample sample = Timer.start(meterRegistry);

        return mongoTemplate.find(
                new Query(Criteria.where("name").regex(keyword, "i")),
                Product.class)
            .doFinally(signalType -&gt;
                sample.stop(Timer.builder("product.search.duration")
                    .description("상품 검색 소요 시간")
                    .tag("signal", signalType.name())
                    .publishPercentiles(0.5, 0.95, 0.99)
                    .publishPercentileHistogram()
                    .register(meterRegistry)));
    }
}</code></pre>
<p><code>publishPercentiles</code>로 p50, p95, p99 레이턴시를 Grafana에서 바로 확인할 수 있다.</p>
<h3 id="1826">18.2.6 공통 태그와 메트릭 사전 등록</h3>
<pre class="highlight"><code class="language-java">@Configuration
public class MetricsConfig {

    @Bean
    public MeterRegistryCustomizer&lt;MeterRegistry&gt; commonTags() {
        return registry -&gt; registry.config()
            .commonTags(
                "application", "webflux-shop",
                "environment", System.getenv().getOrDefault("ENV", "local")
            );
    }

    @Bean
    public Timer externalApiTimer(MeterRegistry registry) {
        return Timer.builder("external.api.duration")
            .description("외부 API 호출 소요 시간")
            .publishPercentiles(0.5, 0.95, 0.99)
            .register(registry);
    }
}</code></pre>
<h3 id="1827-prometheus-prometheusyml">18.2.7 Prometheus 설정 (prometheus.yml)</h3>
<p>Prometheus가 애플리케이션의 메트릭을 주기적으로 스크래핑하도록 설정한다.</p>
<pre class="highlight"><code class="language-yaml"># prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'webflux-app'
    metrics_path: '/actuator/prometheus'
    scrape_interval: 10s
    static_configs:
      - targets: ['host.docker.internal:8080']
        labels:
          app: 'webflux-shop'
          env: 'development'

  - job_name: 'webflux-cluster'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets:
          - 'webflux-app-1:9090'
          - 'webflux-app-2:9090'
          - 'webflux-app-3:9090'</code></pre>
<p>Docker Compose로 Prometheus를 실행한다. Prometheus UI(<code>http://localhost:9090</code>)에서 <code>up{job="webflux-app"}</code> 쿼리로 타겟 연결 상태를 확인할 수 있다.</p>
<pre class="highlight"><code class="language-yaml"># docker-compose-monitoring.yml
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml</code></pre>
<hr>
<h2 id="183-grafana">18.3 Grafana 대시보드 구성</h2>
<h3 id="1831-grafana-docker">18.3.1 Grafana Docker 설치와 데이터소스 연결</h3>
<p>기존 <code>docker-compose-monitoring.yml</code>에 Grafana를 추가한다.</p>
<pre class="highlight"><code class="language-yaml">services:
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin123
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus</code></pre>
<p><code>docker compose -f docker-compose-monitoring.yml up -d</code>로 실행한 후, <code>http://localhost:3000</code>에 접속하여 로그인한다. 프로비저닝 기능으로 Prometheus 데이터소스를 자동 등록한다.</p>
<pre class="highlight"><code class="language-yaml"># grafana/provisioning/datasources/prometheus.yml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true</code></pre>
<h3 id="1833">18.3.3 대시보드 임포트</h3>
<p>Grafana 커뮤니티에서 제공하는 대시보드를 임포트하면 빠르게 모니터링 환경을 구축할 수 있다.</p>
<table>
<thead>
<tr>
<th>대시보드 ID</th>
<th>이름</th>
<th>용도</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>4701</strong></td>
<td>JVM (Micrometer)</td>
<td>JVM 메모리, GC, 스레드 모니터링</td>
</tr>
<tr>
<td><strong>11378</strong></td>
<td>Spring Boot Statistics</td>
<td>HTTP 요청, 에러율, 응답 시간</td>
</tr>
<tr>
<td><strong>12900</strong></td>
<td>Spring Boot Observability</td>
<td>종합 관측 가능성</td>
</tr>
</tbody>
</table>
<p>Grafana UI에서 <strong>Dashboards &gt; Import</strong> 메뉴로 이동하여 대시보드 ID를 입력하면 된다.</p>
<h3 id="1834-promql">18.3.4 커스텀 대시보드 PromQL 쿼리</h3>
<p>프로젝트에 맞는 커스텀 패널을 구성할 때 자주 사용하는 PromQL 쿼리는 다음과 같다.</p>
<p><strong>초당 요청 수 (RPS)</strong>:
<pre class="highlight"><code class="language-promql">rate(http_server_requests_seconds_count{application="webflux-shop"}[5m])</code></pre></p>
<p><strong>95번째 백분위 응답 시간</strong>:
<pre class="highlight"><code class="language-promql">histogram_quantile(0.95,
  rate(http_server_requests_seconds_bucket{application="webflux-shop"}[5m]))</code></pre></p>
<p><strong>에러율 (%)</strong>:
<pre class="highlight"><code class="language-promql">sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m]))
/
sum(rate(http_server_requests_seconds_count[5m]))
* 100</code></pre></p>
<h3 id="1835">18.3.5 알림 규칙 설정</h3>
<p>Grafana의 알림 기능으로 이상 상태를 감지하고 Slack, Email, PagerDuty 등으로 알림을 발송한다. Grafana UI의 <strong>Alerting &gt; Alert Rules &gt; New alert rule</strong>에서 생성하며, 주요 설정 항목은 다음과 같다.</p>
<table>
<thead>
<tr>
<th>설정 항목</th>
<th>값</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Rule name</strong></td>
<td>높은 에러율 경고</td>
<td>알림 규칙 이름</td>
</tr>
<tr>
<td><strong>Query</strong></td>
<td>위 에러율 PromQL</td>
<td>감시 대상 쿼리</td>
</tr>
<tr>
<td><strong>Threshold</strong></td>
<td><code>&gt; 5</code></td>
<td>에러율 5% 초과 시</td>
</tr>
<tr>
<td><strong>Pending period</strong></td>
<td><code>5m</code></td>
<td>5분간 지속 시 알림 발생</td>
</tr>
</tbody>
</table>
<p>알림 채널은 <strong>Alerting &gt; Contact points</strong>에서 설정한다.</p>
<hr>
<h2 id="184">18.4 리액티브 스트림 메트릭 수집</h2>
<h3 id="1841-reactor">18.4.1 Reactor 메트릭 활성화</h3>
<p>Reactor는 Micrometer와 통합된 내장 메트릭 기능을 제공한다. 이를 활성화하면 Reactor 파이프라인 내부의 구독 상태, 요청 수, 에러 등을 추적할 수 있다.</p>
<pre class="highlight"><code class="language-java">@SpringBootApplication
public class WebFluxApplication {

    public static void main(String[] args) {
        Hooks.enableAutomaticContextPropagation();
        Schedulers.enableMetrics();
        SpringApplication.run(WebFluxApplication.class, args);
    }
}</code></pre>
<h3 id="1842">18.4.2 개별 연산자 메트릭 수집</h3>
<p>특정 Reactor 체인에 <code>.name()</code>과 <code>.tag()</code> 연산자를 사용하여 세밀한 메트릭을 수집한다. <code>.metrics()</code>를 체인 끝에 추가하면 해당 시점까지의 메트릭이 Micrometer로 기록된다.</p>
<pre class="highlight"><code class="language-java">@Service
@RequiredArgsConstructor
public class NotificationService {

    private final ReactiveMongoTemplate mongoTemplate;

    public Flux&lt;Notification&gt; getUnreadNotifications(String userId) {
        return mongoTemplate.find(
                Query.query(Criteria.where("userId").is(userId)
                    .and("read").is(false)),
                Notification.class)
            .name("notification.unread.fetch")
            .tag("type", "unread")
            .metrics();
    }
}</code></pre>
<p>이렇게 하면 다음 메트릭이 자동으로 생성된다.</p>
<table>
<thead>
<tr>
<th>메트릭 이름</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>reactor.notification.unread.fetch.subscribed</code></td>
<td>구독 횟수</td>
</tr>
<tr>
<td><code>reactor.notification.unread.fetch.requested</code></td>
<td>요청된 요소 수</td>
</tr>
<tr>
<td><code>reactor.notification.unread.fetch.onNext.delay</code></td>
<td>onNext 신호 간의 지연 시간</td>
</tr>
<tr>
<td><code>reactor.notification.unread.fetch.flow.duration</code></td>
<td>전체 실행 시간</td>
</tr>
</tbody>
</table>
<h3 id="1843-schedulers">18.4.3 Schedulers 메트릭</h3>
<p><code>Schedulers.enableMetrics()</code> 호출 후 수집되는 스케줄러 관련 메트릭은 다음과 같다.</p>
<table>
<thead>
<tr>
<th>메트릭</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>executor_pool_size_threads</code></td>
<td>현재 스레드 풀 크기</td>
</tr>
<tr>
<td><code>executor_active_threads</code></td>
<td>활성 스레드 수</td>
</tr>
<tr>
<td><code>executor_queued_tasks</code></td>
<td>대기열 태스크 수</td>
</tr>
<tr>
<td><code>executor_completed_tasks_total</code></td>
<td>완료된 태스크 수</td>
</tr>
</tbody>
</table>
<p>이름을 부여한 커스텀 스케줄러를 생성하면 스케줄러별로 메트릭을 구분하여 모니터링할 수 있다.</p>
<pre class="highlight"><code class="language-java">@Configuration
public class SchedulerMetricsConfig {

    @Bean
    public Scheduler metricsEnabledBoundedElastic() {
        return Schedulers.newBoundedElastic(
            Schedulers.DEFAULT_BOUNDED_ELASTIC_SIZE,
            Schedulers.DEFAULT_BOUNDED_ELASTIC_QUEUESIZE,
            "custom-bounded-elastic"
        );
    }
}</code></pre>
<hr>
<h2 id="185-zipkin-jaeger">18.5 분산 추적 (Zipkin / Jaeger)</h2>
<h3 id="1851">18.5.1 분산 추적의 필요성</h3>
<p>마이크로서비스 환경에서 하나의 사용자 요청은 여러 서비스를 거쳐 처리된다. 분산 추적은 이 과정을 <strong>Trace ID</strong>와 <strong>Span ID</strong>로 연결하여 전체 호출 흐름을 시각화한다.</p>
<pre class="highlight"><code>[사용자 요청]
  └─ Trace ID: abc123
      ├─ Span 1: API Gateway (10ms)
      ├─ Span 2: Product Service (25ms)
      │   └─ Span 3: MongoDB 쿼리 (8ms)
      └─ Span 4: Order Service (30ms)
          └─ Span 5: Payment API 호출 (20ms)</code></pre>
<h3 id="1852-micrometer-tracing">18.5.2 Micrometer Tracing 설정</h3>
<p>Spring Boot 3.x에서는 Micrometer Tracing이 분산 추적의 표준 추상화 계층이다. Brave(Zipkin) 또는 OpenTelemetry 브릿지를 선택할 수 있다.</p>
<p><strong>Zipkin을 사용하는 경우</strong>:</p>
<pre class="highlight"><code class="language-groovy">dependencies {
    implementation 'io.micrometer:micrometer-tracing-bridge-brave'
    implementation 'io.zipkin.reporter2:zipkin-reporter-brave'
}</code></pre>
<p><strong>Jaeger를 사용하는 경우 (OpenTelemetry)</strong>:</p>
<pre class="highlight"><code class="language-groovy">dependencies {
    implementation 'io.micrometer:micrometer-tracing-bridge-otel'
    implementation 'io.opentelemetry:opentelemetry-exporter-zipkin'
}</code></pre>
<blockquote>
<p><strong>참고</strong>: Jaeger는 Zipkin 호환 프로토콜을 지원하므로, Zipkin 리포터로도 Jaeger에 데이터를 전송할 수 있다. 최신 Jaeger는 OTLP(OpenTelemetry Protocol)를 기본 수집 프로토콜로 권장한다.</p>
</blockquote>
<h3 id="1853-applicationyml">18.5.3 application.yml 설정</h3>
<pre class="highlight"><code class="language-yaml">management:
  tracing:
    sampling:
      probability: 1.0        # 개발: 100%, 운영: 0.1 (10%) 권장
    propagation:
      type: b3                 # W3C 또는 B3 전파 형식
  zipkin:
    tracing:
      endpoint: http://localhost:9411/api/v2/spans

logging:
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] [%X{traceId}/%X{spanId}] %-5level %logger{36} - %msg%n"</code></pre>
<h3 id="1854-zipkin-jaeger-docker">18.5.4 Zipkin / Jaeger Docker 설치</h3>
<p>Zipkin은 <code>docker run -d -p 9411:9411 openzipkin/zipkin</code>으로 간단히 실행할 수 있다. Jaeger를 사용하는 경우 다음과 같이 설정한다.</p>
<pre class="highlight"><code class="language-yaml">services:
  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"    # Jaeger UI
      - "9411:9411"      # Zipkin 호환 포트
      - "4317:4317"      # OTLP gRPC
    environment:
      COLLECTOR_ZIPKIN_HOST_PORT: ":9411"</code></pre>
<p>Zipkin UI는 <code>http://localhost:9411</code>, Jaeger UI는 <code>http://localhost:16686</code>에서 접근한다.</p>
<h3 id="1855-webclient-trace">18.5.5 WebClient에서의 Trace 전파</h3>
<p><code>WebClient</code>를 <code>WebClient.Builder</code> 빈으로 생성하면 Micrometer Tracing이 자동으로 Trace 전파 필터를 추가한다. 중요한 점은 <code>WebClient.create()</code> 대신 반드시 스프링이 관리하는 <code>WebClient.Builder</code>를 주입받아 사용해야 한다는 것이다.</p>
<pre class="highlight"><code class="language-java">@Configuration
public class WebClientConfig {

    @Bean
    public WebClient externalServiceClient(WebClient.Builder builder) {
        // Builder 빈을 주입받으면 Tracing 필터가 자동 추가됨
        return builder
            .baseUrl("https://external-service.example.com")
            .build();
    }
}</code></pre>
<p>이렇게 생성한 <code>WebClient</code>로 외부 API를 호출하면, Trace ID가 요청 헤더에 자동으로 포함되어 전파된다. Zipkin UI에서 트레이스를 조회하면 MongoDB 조회와 외부 API 호출이 별도의 Span으로 기록되고 동일한 Trace ID로 묶인 것을 확인할 수 있다.</p>
<h3 id="1856-span">18.5.6 커스텀 Span 생성</h3>
<p>자동 계측으로 충분하지 않은 경우, <code>@Observed</code> 어노테이션으로 메서드 단위 Span을 생성하거나, <code>Observation</code> API로 수동 제어한다.</p>
<pre class="highlight"><code class="language-java">@Service
public class InventoryService {

    @Observed(name = "inventory.check",
              contextualName = "check-inventory",
              lowCardinalityKeyValues = {"inventory.type", "product"})
    public Mono&lt;Boolean&gt; checkAvailability(String productId, int quantity) {
        return Mono.just(true);
    }
}</code></pre>
<p><code>@Observed</code>를 사용하려면 <code>ObservedAspect</code> 빈을 등록해야 한다.</p>
<pre class="highlight"><code class="language-java">@Configuration
public class ObservationConfig {

    @Bean
    public ObservedAspect observedAspect(ObservationRegistry registry) {
        return new ObservedAspect(registry);
    }
}</code></pre>
<p><code>Observation</code> API를 사용하면 리액티브 체인 내에서 더 세밀한 Span 제어가 가능하다.</p>
<pre class="highlight"><code class="language-java">@Service
@RequiredArgsConstructor
public class PaymentProcessService {

    private final ObservationRegistry observationRegistry;

    public Mono&lt;PaymentResult&gt; processPayment(PaymentRequest request) {
        Observation observation = Observation.createNotStarted(
                "payment.process", observationRegistry)
            .lowCardinalityKeyValue("payment.method", request.getPaymentMethod());

        return Mono.just(request)
            .flatMap(this::validatePayment)
            .flatMap(this::executePayment)
            .doOnSubscribe(s -&gt; observation.start())
            .doOnTerminate(observation::stop)
            .doOnError(observation::error);
    }
}</code></pre>
<hr>
<h2 id="186-logback-mdc-in-reactive">18.6 구조화된 로깅 (Logback + MDC in Reactive)</h2>
<h3 id="1861">18.6.1 구조화된 로깅의 필요성</h3>
<p>운영 환경에서 텍스트 기반 로그는 검색과 집계가 어렵다. ELK(Elasticsearch + Logstash + Kibana)나 Loki 같은 로그 수집 시스템과 연동하려면 <strong>JSON 형식</strong> 로그가 효과적이다.</p>
<pre class="highlight"><code># 기존 텍스트 로그
2026-02-14 10:30:15.123 [reactor-http-nio-3] INFO c.e.s.OrderService - 주문 생성 완료: orderId=abc123</code></pre>
<pre class="highlight"><code class="language-json">// 구조화된 JSON 로그
{
  "timestamp": "2026-02-14T10:30:15.123Z",
  "level": "INFO",
  "logger": "com.example.shop.OrderService",
  "message": "주문 생성 완료",
  "traceId": "6a3f7b2c1d4e5f",
  "spanId": "a1b2c3d4",
  "orderId": "abc123",
  "userId": "user-456",
  "service": "webflux-shop"
}</code></pre>
<h3 id="1862-logback-json">18.6.2 Logback JSON 설정</h3>
<p><code>logstash-logback-encoder</code>를 사용하여 JSON 형식 로그를 출력한다.</p>
<pre class="highlight"><code class="language-groovy">dependencies {
    implementation 'net.logstash.logback:logstash-logback-encoder:7.4'
}</code></pre>
<pre class="highlight"><code class="language-xml">&lt;!-- src/main/resources/logback-spring.xml --&gt;
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;configuration&gt;
    &lt;springProperty scope="context" name="APP_NAME"
                    source="spring.application.name" defaultValue="webflux-app"/&gt;

    &lt;!-- 개발 환경: 텍스트 로그 --&gt;
    &lt;springProfile name="local,dev"&gt;
        &lt;appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt;
            &lt;encoder&gt;
                &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] [%X{traceId:-}/%X{spanId:-}] %-5level %logger{36} - %msg%n&lt;/pattern&gt;
            &lt;/encoder&gt;
        &lt;/appender&gt;
        &lt;root level="INFO"&gt;&lt;appender-ref ref="CONSOLE"/&gt;&lt;/root&gt;
    &lt;/springProfile&gt;

    &lt;!-- 운영 환경: JSON 로그 --&gt;
    &lt;springProfile name="prod,staging"&gt;
        &lt;appender name="JSON_CONSOLE" class="ch.qos.logback.core.ConsoleAppender"&gt;
            &lt;encoder class="net.logstash.logback.encoder.LogstashEncoder"&gt;
                &lt;includeMdcKeyName&gt;traceId&lt;/includeMdcKeyName&gt;
                &lt;includeMdcKeyName&gt;spanId&lt;/includeMdcKeyName&gt;
                &lt;includeMdcKeyName&gt;userId&lt;/includeMdcKeyName&gt;
                &lt;includeMdcKeyName&gt;requestId&lt;/includeMdcKeyName&gt;
                &lt;customFields&gt;{"service":"${APP_NAME}"}&lt;/customFields&gt;
                &lt;timeZone&gt;UTC&lt;/timeZone&gt;
            &lt;/encoder&gt;
        &lt;/appender&gt;
        &lt;root level="INFO"&gt;&lt;appender-ref ref="JSON_CONSOLE"/&gt;&lt;/root&gt;
    &lt;/springProfile&gt;
&lt;/configuration&gt;</code></pre>
<h3 id="1863-mdc">18.6.3 리액티브 환경에서의 MDC 문제와 해결</h3>
<p>전통적인 서블릿 환경에서 MDC는 <code>ThreadLocal</code> 기반으로 동작한다. 그러나 리액티브 환경에서는 하나의 요청이 여러 스레드를 넘나들며 처리되므로, <code>publishOn()</code>이나 <code>subscribeOn()</code>으로 스레드가 전환되면 MDC 값이 유실된다.</p>
<p>Spring Boot 3.x에서는 <code>context-propagation</code> 라이브러리와 <code>Hooks.enableAutomaticContextPropagation()</code>으로 이 문제를 해결한다. 18.4.1에서 설정한 것처럼 이를 활성화하면 <code>traceId</code>와 <code>spanId</code>가 자동으로 MDC에 전파된다. 비즈니스 컨텍스트(<code>userId</code>, <code>requestId</code>)를 추가로 전파하려면 <code>WebFilter</code>와 <code>ThreadLocalAccessor</code>를 구현한다.</p>
<h3 id="1864">18.6.4 커스텀 컨텍스트 전파</h3>
<p><code>WebFilter</code>에서 Reactor Context에 값을 저장하고, <code>ThreadLocalAccessor</code>를 통해 MDC와 연결한다.</p>
<pre class="highlight"><code class="language-java">@Component
@Order(Ordered.HIGHEST_PRECEDENCE)
public class ContextPropagationFilter implements WebFilter {

    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange,
                             WebFilterChain chain) {
        String requestId = Optional.ofNullable(
                exchange.getRequest().getHeaders().getFirst("X-Request-Id"))
            .orElse(UUID.randomUUID().toString().substring(0, 12));

        return exchange.getPrincipal()
            .map(Principal::getName)
            .defaultIfEmpty("anonymous")
            .flatMap(userId -&gt; chain.filter(exchange)
                .contextWrite(ctx -&gt; ctx
                    .put("requestId", requestId)
                    .put("userId", userId)));
    }
}</code></pre>
<p><code>ThreadLocalAccessor</code>를 구현하여 Reactor Context와 MDC 간의 자동 전파를 설정한다.</p>
<pre class="highlight"><code class="language-java">public class UserIdThreadLocalAccessor implements ThreadLocalAccessor&lt;String&gt; {

    public static final String KEY = "userId";

    @Override
    public Object key() { return KEY; }

    @Override
    public String getValue() { return MDC.get(KEY); }

    @Override
    public void setValue(String value) { MDC.put(KEY, value); }

    @Override
    public void setValue() { MDC.remove(KEY); }
}</code></pre>
<p><code>ThreadLocalAccessor</code> 구현체는 <code>ContextRegistry</code>에 등록한다. <code>requestId</code>용도 동일한 패턴으로 구현한다.</p>
<pre class="highlight"><code class="language-java">@Configuration
public class ContextPropagationConfig {

    @PostConstruct
    public void init() {
        ContextRegistry.getInstance()
            .registerThreadLocalAccessor(new UserIdThreadLocalAccessor());
        ContextRegistry.getInstance()
            .registerThreadLocalAccessor(new RequestIdThreadLocalAccessor());
    }
}</code></pre>
<p>이제 스레드가 전환되더라도 <code>userId</code>와 <code>requestId</code>가 MDC에 자동 전파되며, JSON 로그에 포함된다.</p>
<h3 id="1865">18.6.5 구조화된 로그 작성 패턴</h3>
<p><code>logstash-logback-encoder</code>의 <code>StructuredArguments</code>를 사용하면 로그 메시지와 JSON 필드를 동시에 기록할 수 있다.</p>
<pre class="highlight"><code class="language-java">import static net.logstash.logback.argument.StructuredArguments.*;

@Service
@Slf4j
@RequiredArgsConstructor
public class OrderService {

    private final OrderRepository orderRepository;

    public Mono&lt;Order&gt; createOrder(OrderRequest request) {
        return orderRepository.save(Order.from(request))
            .doOnSuccess(order -&gt;
                log.info("주문 생성 완료: {} {} {}",
                    keyValue("orderId", order.getId()),
                    keyValue("amount", order.getTotalAmount()),
                    keyValue("items", order.getItems().size())))
            .doOnError(ex -&gt;
                log.error("주문 생성 실패: {} {}",
                    keyValue("userId", request.getUserId()),
                    keyValue("error", ex.getMessage()), ex));
        // JSON: {"message":"주문 생성 완료: orderId=abc amount=15000 items=3",
        //        "orderId":"abc", "amount":15000, "items":3, ...}
    }
}</code></pre>
<hr>
<h2 id="_1">요약</h2>
<table>
<thead>
<tr>
<th>주제</th>
<th>핵심 내용</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Actuator</strong></td>
<td><code>health</code>, <code>info</code>, <code>metrics</code>, <code>prometheus</code> 엔드포인트 노출, <code>ReactiveHealthIndicator</code>로 논블로킹 상태 확인, 포트 분리와 Security 연동으로 보안 강화</td>
</tr>
<tr>
<td><strong>Micrometer + Prometheus</strong></td>
<td><code>Counter</code>(단조 증가), <code>Gauge</code>(현재 값), <code>Timer</code>(소요 시간 + 호출 수) 커스텀 메트릭, <code>prometheus.yml</code>로 스크래핑 설정</td>
</tr>
<tr>
<td><strong>Grafana</strong></td>
<td>Docker 설치, Prometheus 데이터소스 프로비저닝, 커뮤니티 대시보드 임포트, PromQL로 커스텀 패널, 알림 규칙 설정</td>
</tr>
<tr>
<td><strong>리액티브 메트릭</strong></td>
<td><code>.name().tag().metrics()</code>로 Reactor 체인 메트릭 수집, <code>Schedulers.enableMetrics()</code>로 스케줄러 모니터링</td>
</tr>
<tr>
<td><strong>분산 추적</strong></td>
<td>Micrometer Tracing + Brave(Zipkin) 또는 OpenTelemetry(Jaeger), <code>WebClient.Builder</code> 빈으로 자동 Trace 전파, <code>@Observed</code>로 커스텀 Span</td>
</tr>
<tr>
<td><strong>구조화된 로깅</strong></td>
<td><code>logstash-logback-encoder</code>로 JSON 로그, <code>Hooks.enableAutomaticContextPropagation()</code>으로 Reactor Context-MDC 자동 전파, <code>ThreadLocalAccessor</code>로 커스텀 컨텍스트 전파</td>
</tr>
</tbody>
</table>
<p>다음 장에서는 리액티브 애플리케이션의 성능을 측정하고 최적화하는 전략을 다룬다. MongoDB 커넥션 풀 튜닝, Netty 이벤트 루프 최적화, 캐싱, BlockHound를 활용한 블로킹 코드 탐지, 그리고 Gatling/k6를 이용한 부하 테스트까지 실전 성능 최적화 기법을 종합적으로 살펴본다.</p>
    </main>
    <footer class="site-footer">
      &copy; 2024 Spring Boot + WebFlux + JPA (MongoDB) Book
    </footer>
  </div>
</body>
</html>