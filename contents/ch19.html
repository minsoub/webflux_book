<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Chapter 19. 성능 최적화 | Spring Boot + WebFlux + JPA (MongoDB)</title>
  <link rel="stylesheet" href="../css/style.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
</head>
<body>
  <header class="site-header">
    <h1><a href="../index.html">Spring Boot + WebFlux + JPA (MongoDB)</a></h1>
  </header>
    <nav class="nav-bar">
    <a href="ch18.html">&larr; Chapter 18. 모니터링과 관측 가능성</a>
    <a href="../index.html">목차</a>
    <a href="ch20.html">Chapter 20. 컨테이너화와 배포 &rarr;</a>
  </nav>
  <div class="wrapper">
    <main class="content">
      <h1 id="chapter-19">Chapter 19. 성능 최적화</h1>
<p>리액티브 아키텍처를 도입했다고 해서 자동으로 높은 성능이 보장되는 것은 아니다. 논블로킹 모델의 이점을 실제로 누리려면, 병목 지점을 정확히 측정하고, 커넥션 풀과 이벤트 루프를 애플리케이션 특성에 맞게 조정하며, 캐싱으로 불필요한 I/O를 줄이고, 블로킹 코드를 철저히 제거해야 한다. 이번 장에서는 리액티브 애플리케이션의 <strong>성능 측정 방법</strong>부터 <strong>MongoDB 커넥션 풀 튜닝</strong>, <strong>Netty 이벤트 루프 최적화</strong>, <strong>캐싱 전략</strong>, <strong>BlockHound를 활용한 블로킹 탐지</strong>, 그리고 <strong>Gatling/k6를 활용한 부하 테스트</strong>까지 실전 성능 최적화의 전 과정을 다룬다.</p>
<hr>
<h2 id="191">19.1 리액티브 애플리케이션 성능 측정</h2>
<p>성능 최적화의 첫 번째 원칙은 <strong>측정 없이 최적화하지 않는 것</strong>이다. 감에 의존한 최적화는 오히려 코드 복잡도만 높이고 실질적인 개선을 가져오지 못한다.</p>
<h3 id="1911">19.1.1 핵심 성능 지표</h3>
<p>리액티브 애플리케이션의 성능은 세 가지 축으로 평가한다.</p>
<table>
<thead>
<tr>
<th>지표</th>
<th>설명</th>
<th>측정 단위</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>처리량(Throughput)</strong></td>
<td>단위 시간당 처리한 요청 수</td>
<td>req/sec</td>
</tr>
<tr>
<td><strong>지연시간(Latency)</strong></td>
<td>요청 시작부터 응답 완료까지 소요 시간</td>
<td>ms (p50, p95, p99)</td>
</tr>
<tr>
<td><strong>리소스 사용률</strong></td>
<td>CPU, 메모리, 스레드, 커넥션 점유율</td>
<td>%, 개수</td>
</tr>
</tbody>
</table>
<p>리액티브 애플리케이션은 적은 스레드로 높은 처리량을 달성하는 것이 목표다. 따라서 스레드 수 대비 처리량 비율이 중요한 평가 기준이 된다. 지연시간은 단순 평균보다 백분위(p95, p99)를 기준으로 판단해야 실제 사용자 경험을 반영할 수 있다.</p>
<pre class="highlight"><code>[전통적 MVC 모델]
스레드 200개 → 동시 처리 200 요청 → 처리량 ~2,000 req/sec

[리액티브 모델]
스레드 8개(이벤트 루프) → 동시 처리 수천 요청 → 처리량 ~10,000+ req/sec</code></pre>
<h3 id="1912-micrometer">19.1.2 Micrometer 메트릭 활용</h3>
<p>Chapter 18에서 설정한 Micrometer 메트릭을 성능 분석에 활용한다. WebFlux 애플리케이션에서 자동 수집되는 핵심 메트릭은 다음과 같다.</p>
<table>
<thead>
<tr>
<th>메트릭 이름</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>http.server.requests</code></td>
<td>HTTP 요청 처리 시간 (타이머)</td>
</tr>
<tr>
<td><code>reactor.netty.http.server.data.received</code></td>
<td>서버가 수신한 데이터 바이트</td>
</tr>
<tr>
<td><code>mongodb.driver.pool.size</code></td>
<td>MongoDB 커넥션 풀 크기</td>
</tr>
<tr>
<td><code>mongodb.driver.pool.waitqueuesize</code></td>
<td>MongoDB 커넥션 대기 큐 크기</td>
</tr>
<tr>
<td><code>jvm.threads.live</code></td>
<td>활성 JVM 스레드 수</td>
</tr>
</tbody>
</table>
<p>커스텀 메트릭을 추가하여 비즈니스 로직의 성능도 측정할 수 있다.</p>
<pre class="highlight"><code class="language-java">@Service
@RequiredArgsConstructor
public class ProductService {

    private final ProductRepository productRepository;
    private final MeterRegistry meterRegistry;

    public Mono&lt;Product&gt; findById(String id) {
        return Mono.defer(() -&gt; {
            Timer.Sample sample = Timer.start(meterRegistry);

            return productRepository.findById(id)
                .doOnSuccess(p -&gt; sample.stop(
                    Timer.builder("product.findById")
                        .tag("result", p != null ? "found" : "not_found")
                        .register(meterRegistry)
                ))
                .doOnError(e -&gt; sample.stop(
                    Timer.builder("product.findById")
                        .tag("result", "error")
                        .register(meterRegistry)
                ));
        });
    }
}</code></pre>
<h3 id="1913-jmh">19.1.3 JMH 마이크로벤치마크</h3>
<p>JMH(Java Microbenchmark Harness)는 JVM 수준의 정밀한 벤치마크 도구다. <code>build.gradle</code>에 JMH 플러그인을 추가한다.</p>
<pre class="highlight"><code class="language-groovy">plugins {
    id 'me.champeau.jmh' version '0.7.2'
}

dependencies {
    jmh 'org.openjdk.jmh:jmh-core:1.37'
    jmh 'org.openjdk.jmh:jmh-generator-annprocess:1.37'
}</code></pre>
<p>Reactor 연산자 체인의 성능을 비교하는 벤치마크 예시를 작성한다.</p>
<pre class="highlight"><code class="language-java">@State(Scope.Thread)
@BenchmarkMode({Mode.Throughput, Mode.AverageTime})
@OutputTimeUnit(TimeUnit.MILLISECONDS)
public class ReactorBenchmark {

    private List&lt;String&gt; items;

    @Setup
    public void setup() {
        items = IntStream.range(0, 10_000)
            .mapToObj(i -&gt; "item-" + i)
            .collect(Collectors.toList());
    }

    @Benchmark
    public void flatMap_동시성_기본값(Blackhole bh) {
        Flux.fromIterable(items)
            .flatMap(item -&gt; Mono.fromCallable(() -&gt; item.toUpperCase()))
            .collectList()
            .block();
    }

    @Benchmark
    public void map_단순변환(Blackhole bh) {
        Flux.fromIterable(items)
            .map(String::toUpperCase)
            .collectList()
            .block();
    }
}</code></pre>
<blockquote>
<p><strong>참고</strong>: <code>map</code>은 동기 변환이므로 <code>flatMap</code>보다 훨씬 빠르다. 비동기 I/O가 불필요한 단순 변환에는 항상 <code>map</code>을 사용해야 한다.</p>
</blockquote>
<h3 id="1914">19.1.4 프로파일링 도구</h3>
<table>
<thead>
<tr>
<th>도구</th>
<th>용도</th>
<th>특징</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>VisualVM</strong></td>
<td>CPU/메모리 프로파일링</td>
<td>무료, JDK 번들</td>
</tr>
<tr>
<td><strong>async-profiler</strong></td>
<td>저오버헤드 CPU/메모리 프로파일링</td>
<td>프로덕션 환경 사용 가능</td>
</tr>
<tr>
<td><strong>JDK Flight Recorder (JFR)</strong></td>
<td>포괄적 런타임 분석</td>
<td>JDK 11+, 프로덕션 안전</td>
</tr>
<tr>
<td><strong>IntelliJ Profiler</strong></td>
<td>IDE 통합 프로파일링</td>
<td>개발 시 편리</td>
</tr>
</tbody>
</table>
<pre class="highlight"><code class="language-bash"># async-profiler 실행 (애플리케이션 PID: 12345)
./asprof -d 30 -f profile.html -e cpu 12345

# JFR 기록 시작
java -XX:+FlightRecorder \
     -XX:StartFlightRecording=duration=60s,filename=recording.jfr \
     -jar application.jar</code></pre>
<p>리액티브 애플리케이션에서 프로파일링 시 주의할 점은, 이벤트 루프 스레드(<code>reactor-http-nio-*</code>)의 CPU 사용률이 80%를 넘으면 병목 가능성이 높다는 것이다. 이 경우 무거운 연산을 별도 스케줄러로 오프로드해야 한다.</p>
<hr>
<h2 id="192-mongodb">19.2 MongoDB 커넥션 풀 튜닝</h2>
<p>MongoDB 드라이버는 내부적으로 커넥션 풀을 관리한다. 풀 크기, 타임아웃, 유휴 커넥션 관리 설정이 처리량에 직접적인 영향을 미친다.</p>
<h3 id="1921">19.2.1 기본 커넥션 풀 동작</h3>
<p>MongoDB Reactive Streams 드라이버의 커넥션 풀 기본값은 다음과 같다.</p>
<table>
<thead>
<tr>
<th>설정</th>
<th>기본값</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>minPoolSize</code></td>
<td>0</td>
<td>최소 유지 커넥션 수</td>
</tr>
<tr>
<td><code>maxPoolSize</code></td>
<td>100</td>
<td>최대 커넥션 수</td>
</tr>
<tr>
<td><code>maxWaitTime</code></td>
<td>120초</td>
<td>커넥션 획득 대기 시간</td>
</tr>
<tr>
<td><code>maxConnectionIdleTime</code></td>
<td>0 (무제한)</td>
<td>유휴 커넥션 유지 시간</td>
</tr>
<tr>
<td><code>maxConnectionLifeTime</code></td>
<td>0 (무제한)</td>
<td>커넥션 최대 수명</td>
</tr>
</tbody>
</table>
<h3 id="1922-mongoclientsettings">19.2.2 MongoClientSettings를 활용한 커넥션 풀 설정</h3>
<p><code>application.yml</code>의 URI 파라미터 방식보다 <code>MongoClientSettings</code> 빈을 직접 구성하면 세밀한 제어가 가능하다.</p>
<pre class="highlight"><code class="language-java">@Configuration
public class MongoConfig extends AbstractReactiveMongoConfiguration {

    @Value("${spring.data.mongodb.uri}")
    private String mongoUri;

    @Override
    protected String getDatabaseName() {
        return "myapp";
    }

    @Override
    @Bean
    public MongoClient reactiveMongoClient() {
        ConnectionString connString = new ConnectionString(mongoUri);

        MongoClientSettings settings = MongoClientSettings.builder()
            .applyConnectionString(connString)
            .applyToConnectionPoolSettings(pool -&gt; pool
                .minSize(10)                                     // 최소 커넥션
                .maxSize(50)                                     // 최대 커넥션
                .maxWaitTime(5, TimeUnit.SECONDS)                // 커넥션 대기 타임아웃
                .maxConnectionIdleTime(30, TimeUnit.SECONDS)     // 유휴 커넥션 정리
                .maxConnectionLifeTime(5, TimeUnit.MINUTES)      // 커넥션 최대 수명
                .maintenanceFrequency(30, TimeUnit.SECONDS)      // 정리 주기
            )
            .applyToSocketSettings(socket -&gt; socket
                .connectTimeout(3, TimeUnit.SECONDS)
                .readTimeout(10, TimeUnit.SECONDS)
            )
            .applyToServerSettings(server -&gt; server
                .heartbeatFrequency(10, TimeUnit.SECONDS)
                .minHeartbeatFrequency(500, TimeUnit.MILLISECONDS)
            )
            .build();

        return MongoClients.create(settings);
    }
}</code></pre>
<h3 id="1923">19.2.3 풀 크기 산정 가이드라인</h3>
<p>커넥션 풀 크기는 다음 공식을 기준으로 산정한다.</p>
<pre class="highlight"><code>최적 풀 크기 = (동시 요청 수) x (평균 쿼리 시간) / (목표 응답 시간)</code></pre>
<p>예를 들어, 동시 요청 500건, 평균 쿼리 시간 10ms, 목표 응답 시간 100ms라면 최적 풀 크기는 <code>500 x 10 / 100 = 50</code>이다.</p>
<table>
<thead>
<tr>
<th>시나리오</th>
<th>minSize</th>
<th>maxSize</th>
<th>근거</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>개발 환경</strong></td>
<td>2</td>
<td>10</td>
<td>리소스 절약</td>
</tr>
<tr>
<td><strong>소규모 서비스</strong></td>
<td>5</td>
<td>30</td>
<td>동시 사용자 ~100명</td>
</tr>
<tr>
<td><strong>중규모 서비스</strong></td>
<td>10</td>
<td>50</td>
<td>동시 사용자 ~1,000명</td>
</tr>
<tr>
<td><strong>대규모 서비스</strong></td>
<td>20</td>
<td>100</td>
<td>동시 사용자 ~10,000명</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>주의</strong>: <code>maxSize</code>를 무조건 크게 잡으면 MongoDB 서버 측 리소스가 고갈될 수 있다. 모든 애플리케이션 인스턴스의 <code>maxSize</code> 합이 MongoDB의 <code>net.maxIncomingConnections</code>(기본 65,536)의 80%를 넘지 않도록 한다.</p>
</blockquote>
<h3 id="1924">19.2.4 커넥션 풀 모니터링과 타임아웃</h3>
<p>커넥션 풀 메트릭을 활성화하고, 타임아웃을 계층별로 설정한다.</p>
<pre class="highlight"><code class="language-yaml"># application.yml
management:
  metrics:
    mongo:
      connectionpool:
        enabled: true
      command:
        enabled: true</code></pre>
<pre class="highlight"><code># Prometheus 메트릭 예시
mongodb_driver_pool_size{server_address="localhost:27017"} 25
mongodb_driver_pool_checkedout{server_address="localhost:27017"} 12
mongodb_driver_pool_waitqueuesize{server_address="localhost:27017"} 0</code></pre>
<p><code>waitqueuesize</code>가 지속적으로 0보다 큰 경우, <code>maxSize</code>를 늘리거나 쿼리 성능을 개선해야 한다는 신호다. 타임아웃은 다음 계층으로 구성한다.</p>
<pre class="highlight"><code>소켓 타임아웃 (connectTimeout, readTimeout)
  └─ 쿼리 타임아웃 (maxTimeMsec)
       └─ Reactor 타임아웃 (timeout 연산자)
            └─ HTTP 응답 타임아웃 (WebFlux 타임아웃)</code></pre>
<pre class="highlight"><code class="language-java">public Flux&lt;Product&gt; findByCategory(String category) {
    Query query = new Query(Criteria.where("category").is(category))
        .maxTimeMsec(5000);  // 쿼리 레벨 타임아웃 (5초)

    return mongoTemplate.find(query, Product.class)
        .timeout(Duration.ofSeconds(10));  // Reactor 레벨 타임아웃
}</code></pre>
<hr>
<h2 id="193-netty">19.3 Netty 이벤트 루프 최적화</h2>
<p>Spring WebFlux는 Reactor Netty를 기본 서버로 사용하며, Netty의 이벤트 루프 설정이 전체 처리량에 직접적인 영향을 미친다.</p>
<h3 id="1931">19.3.1 이벤트 루프 기본 구조</h3>
<pre class="highlight"><code>[Boss EventLoopGroup]       &lt;- 새 커넥션 수락 (accept)
  └─ 스레드 1개 (보통)

[Worker EventLoopGroup]     &lt;- I/O 이벤트 처리 (read/write)
  └─ 스레드 N개 (기본: CPU 코어 수)
    ├─ reactor-http-nio-1
    ├─ reactor-http-nio-2
    └─ reactor-http-nio-N</code></pre>
<h3 id="1932-loopresources">19.3.2 LoopResources를 활용한 이벤트 루프 커스터마이징</h3>
<pre class="highlight"><code class="language-java">@Configuration
public class NettyConfig {

    @Bean
    public NettyReactiveWebServerFactory nettyFactory() {
        NettyReactiveWebServerFactory factory = new NettyReactiveWebServerFactory();

        factory.addServerCustomizers(httpServer -&gt; {
            LoopResources loopResources = LoopResources.create(
                "custom-http",      // 스레드 이름 접두사
                1,                  // selector 스레드 수 (accept)
                Runtime.getRuntime().availableProcessors() * 2,  // worker 스레드 수
                true                // 데몬 스레드 여부
            );

            return httpServer
                .runOn(loopResources)
                .option(ChannelOption.SO_BACKLOG, 2048)          // 연결 대기 큐
                .childOption(ChannelOption.SO_KEEPALIVE, true)   // TCP Keep-Alive
                .childOption(ChannelOption.TCP_NODELAY, true);   // Nagle 알고리즘 비활성화
        });

        return factory;
    }
}</code></pre>
<h3 id="1933-native-transport-epoll-kqueue">19.3.3 Native Transport (Epoll, KQueue)</h3>
<p>JVM의 기본 NIO 대신 운영체제의 네이티브 I/O를 사용하면 성능이 개선된다.</p>
<table>
<thead>
<tr>
<th>Transport</th>
<th>운영체제</th>
<th>장점</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>NIO</strong> (기본)</td>
<td>모든 OS</td>
<td>호환성</td>
</tr>
<tr>
<td><strong>Epoll</strong></td>
<td>Linux</td>
<td>낮은 지연시간, edge-triggered I/O</td>
</tr>
<tr>
<td><strong>KQueue</strong></td>
<td>macOS, BSD</td>
<td>macOS에서 최적 성능</td>
</tr>
</tbody>
</table>
<pre class="highlight"><code class="language-groovy">dependencies {
    // Linux Epoll
    runtimeOnly 'io.netty:netty-transport-native-epoll::linux-x86_64'

    // macOS KQueue (Intel / Apple Silicon)
    runtimeOnly 'io.netty:netty-transport-native-kqueue::osx-x86_64'
    runtimeOnly 'io.netty:netty-transport-native-kqueue::osx-aarch_64'
}</code></pre>
<pre class="highlight"><code class="language-java">@Configuration
public class NativeTransportConfig {

    @Bean
    public NettyReactiveWebServerFactory nettyFactory() {
        NettyReactiveWebServerFactory factory = new NettyReactiveWebServerFactory();

        factory.addServerCustomizers(httpServer -&gt; {
            LoopResources loopResources = LoopResources.create(
                "native-http", 1,
                Runtime.getRuntime().availableProcessors(), true
            );
            return httpServer.runOn(loopResources, true);  // preferNative = true
        });

        return factory;
    }
}</code></pre>
<p><code>preferNative</code>를 <code>true</code>로 설정하면 Reactor Netty가 플랫폼에 맞는 네이티브 Transport를 자동으로 선택한다. 네이티브 라이브러리가 없으면 NIO로 자동 폴백한다.</p>
<h3 id="1934">19.3.4 이벤트 루프 블로킹 방지</h3>
<p>이벤트 루프 스레드에서 절대로 블로킹 작업을 수행해서는 안 된다. 무거운 연산은 별도의 스케줄러로 오프로드한다.</p>
<pre class="highlight"><code class="language-java">@Service
public class ReportService {

    // CPU 집약적 작업 전용 스케줄러
    private final Scheduler cpuScheduler = Schedulers.newParallel(
        "cpu-worker", Runtime.getRuntime().availableProcessors());

    // 레거시 블로킹 코드 전용 스케줄러
    private final Scheduler blockingScheduler = Schedulers.newBoundedElastic(
        100, 10_000, "blocking-worker", 60);

    public Mono&lt;Report&gt; generateReport(String reportId) {
        return loadData(reportId)
            .publishOn(cpuScheduler)         // CPU 작업은 별도 스레드에서
            .map(this::heavyComputation)
            .flatMap(this::saveReport);
    }

    public Mono&lt;LegacyData&gt; callLegacyApi(String id) {
        return Mono.fromCallable(() -&gt; legacyService.getById(id))
            .subscribeOn(blockingScheduler);  // 블로킹 전용 스레드에서 실행
    }
}</code></pre>
<hr>
<h2 id="194-caffeine-redis">19.4 캐싱 전략 (Caffeine, Redis)</h2>
<p>I/O 연산을 줄이는 가장 효과적인 방법은 캐싱이다. 리액티브 애플리케이션에서는 캐시 조회도 논블로킹으로 이루어져야 한다.</p>
<h3 id="1941-caffeine">19.4.1 Caffeine 로컬 캐시</h3>
<p>Caffeine은 JVM 기반의 고성능 로컬 캐시 라이브러리다. 리액티브 환경에서 활용하는 래퍼 클래스를 작성한다.</p>
<pre class="highlight"><code class="language-groovy">dependencies {
    implementation 'com.github.ben-manes.caffeine:caffeine:3.1.8'
}</code></pre>
<pre class="highlight"><code class="language-java">@Component
public class ReactiveCaffeineCache&lt;K, V&gt; {

    private final Cache&lt;K, V&gt; cache;

    public ReactiveCaffeineCache(int maxSize, Duration ttl) {
        this.cache = Caffeine.newBuilder()
            .maximumSize(maxSize)
            .expireAfterWrite(ttl)
            .recordStats()
            .build();
    }

    public Mono&lt;V&gt; get(K key) {
        return Mono.justOrEmpty(cache.getIfPresent(key));
    }

    public Mono&lt;V&gt; get(K key, Function&lt;K, Mono&lt;V&gt;&gt; loader) {
        V cached = cache.getIfPresent(key);
        if (cached != null) {
            return Mono.just(cached);
        }
        return loader.apply(key)
            .doOnNext(value -&gt; cache.put(key, value));
    }

    public Mono&lt;Void&gt; put(K key, V value) {
        cache.put(key, value);
        return Mono.empty();
    }

    public Mono&lt;Void&gt; evict(K key) {
        cache.invalidate(key);
        return Mono.empty();
    }
}</code></pre>
<p>서비스에서 캐시를 활용하는 패턴은 다음과 같다.</p>
<pre class="highlight"><code class="language-java">@Service
public class ProductService {

    private final ProductRepository productRepository;
    private final ReactiveCaffeineCache&lt;String, Product&gt; productCache;

    public ProductService(ProductRepository productRepository) {
        this.productRepository = productRepository;
        this.productCache = new ReactiveCaffeineCache&lt;&gt;(10_000, Duration.ofMinutes(5));
    }

    public Mono&lt;Product&gt; findById(String id) {
        return productCache.get(id, key -&gt; productRepository.findById(key));
    }

    public Mono&lt;Product&gt; update(String id, ProductUpdateRequest request) {
        return productRepository.findById(id)
            .flatMap(product -&gt; {
                product.setName(request.getName());
                product.setPrice(request.getPrice());
                return productRepository.save(product);
            })
            .doOnNext(product -&gt; productCache.put(id, product));
    }

    public Mono&lt;Void&gt; delete(String id) {
        return productRepository.deleteById(id)
            .then(productCache.evict(id));
    }
}</code></pre>
<h3 id="1942-reactive-redis">19.4.2 Reactive Redis 분산 캐시</h3>
<p>멀티 인스턴스 환경에서는 Reactive Redis를 분산 캐시로 활용한다.</p>
<pre class="highlight"><code class="language-groovy">dependencies {
    implementation 'org.springframework.boot:spring-boot-starter-data-redis-reactive'
}</code></pre>
<pre class="highlight"><code class="language-yaml">spring:
  data:
    redis:
      host: localhost
      port: 6379
      timeout: 3s
      lettuce:
        pool:
          max-active: 50
          max-idle: 10
          min-idle: 5</code></pre>
<pre class="highlight"><code class="language-java">@Service
@RequiredArgsConstructor
public class RedisCacheService {

    private final ReactiveStringRedisTemplate redisTemplate;
    private final ObjectMapper objectMapper;

    public &lt;T&gt; Mono&lt;T&gt; getOrLoad(String key, Class&lt;T&gt; type,
                                  Duration ttl, Mono&lt;T&gt; loader) {
        return redisTemplate.opsForValue()
            .get(key)
            .flatMap(json -&gt; deserialize(json, type))
            .switchIfEmpty(
                loader.flatMap(value -&gt;
                    serialize(value)
                        .flatMap(json -&gt;
                            redisTemplate.opsForValue()
                                .set(key, json, ttl)
                                .thenReturn(value)
                        )
                )
            );
    }

    public Mono&lt;Boolean&gt; evict(String key) {
        return redisTemplate.delete(key).map(count -&gt; count &gt; 0);
    }

    private &lt;T&gt; Mono&lt;T&gt; deserialize(String json, Class&lt;T&gt; type) {
        return Mono.fromCallable(() -&gt; objectMapper.readValue(json, type))
            .onErrorResume(e -&gt; Mono.empty());  // 역직렬화 실패 시 캐시 미스 처리
    }

    private &lt;T&gt; Mono&lt;String&gt; serialize(T value) {
        return Mono.fromCallable(() -&gt; objectMapper.writeValueAsString(value));
    }
}</code></pre>
<h3 id="1943">19.4.3 멀티 레벨 캐시 전략</h3>
<p>로컬 캐시(Caffeine)와 분산 캐시(Redis)를 조합하여 <strong>L1/L2 캐시</strong> 구조를 구성하면 성능과 일관성을 모두 확보할 수 있다.</p>
<pre class="highlight"><code class="language-java">@Service
public class MultiLevelCacheService&lt;T&gt; {

    private final ReactiveCaffeineCache&lt;String, T&gt; l1Cache;   // 로컬
    private final RedisCacheService redisCacheService;         // 분산

    public MultiLevelCacheService(RedisCacheService redisCacheService) {
        this.l1Cache = new ReactiveCaffeineCache&lt;&gt;(5_000, Duration.ofMinutes(1));
        this.redisCacheService = redisCacheService;
    }

    public Mono&lt;T&gt; get(String key, Class&lt;T&gt; type,
                       Duration redisTtl, Mono&lt;T&gt; loader) {
        // L1 (Caffeine) -&gt; L2 (Redis) -&gt; 원본 데이터 소스
        return l1Cache.get(key)
            .switchIfEmpty(
                redisCacheService.getOrLoad(key, type, redisTtl, loader)
                    .doOnNext(value -&gt; l1Cache.put(key, value))
            );
    }

    public Mono&lt;Void&gt; evict(String key) {
        return l1Cache.evict(key)
            .then(redisCacheService.evict(key))
            .then();
    }
}</code></pre>
<pre class="highlight"><code>요청 -&gt; [L1 Caffeine 캐시] --히트--&gt; 즉시 반환 (&lt; 1ms)
              | 미스
              v
       [L2 Redis 캐시]    --히트--&gt; L1에 저장 후 반환 (~1-3ms)
              | 미스
              v
       [MongoDB 조회]     -------&gt; L1+L2에 저장 후 반환 (~5-50ms)</code></pre>
<hr>
<h2 id="195-blockhound">19.5 블로킹 코드 탐지 및 제거 (BlockHound)</h2>
<p>리액티브 애플리케이션에서 가장 위험한 성능 저하 원인은 <strong>이벤트 루프 스레드에서의 블로킹 호출</strong>이다. 단 한 줄의 블로킹 코드가 전체 처리량을 극적으로 떨어뜨릴 수 있다. BlockHound는 이러한 블로킹 호출을 런타임에 자동으로 탐지하는 Java Agent 도구다.</p>
<h3 id="1951-blockhound">19.5.1 BlockHound 설정</h3>
<pre class="highlight"><code class="language-groovy">dependencies {
    testImplementation 'io.projectreactor.tools:blockhound:1.0.9.RELEASE'
}</code></pre>
<pre class="highlight"><code class="language-java">@SpringBootTest
class ApplicationBlockingTest {

    @BeforeAll
    static void setup() {
        BlockHound.install();
    }

    @Test
    void 블로킹_호출_없음_검증() {
        Mono.delay(Duration.ofMillis(1))
            .doOnNext(it -&gt; {
                // 이벤트 루프 스레드에서 실행됨
                // 여기서 블로킹 호출이 있으면 예외 발생
            })
            .block();
    }
}</code></pre>
<h3 id="1952">19.5.2 흔한 블로킹 코드 패턴과 수정</h3>
<p>리액티브 애플리케이션에서 자주 발견되는 블로킹 코드 패턴과 수정 방법을 정리한다.</p>
<p><strong>패턴 1: 파일 I/O</strong></p>
<pre class="highlight"><code class="language-java">// 블로킹 (위험)
public Mono&lt;String&gt; readFile(String path) {
    return Mono.just(Files.readString(Path.of(path)));  // 블로킹!
}

// 논블로킹 (수정)
public Mono&lt;String&gt; readFile(String path) {
    return Mono.fromCallable(() -&gt; Files.readString(Path.of(path)))
        .subscribeOn(Schedulers.boundedElastic());
}</code></pre>
<p><strong>패턴 2: Thread.sleep()</strong></p>
<pre class="highlight"><code class="language-java">// 블로킹 (위험)
return Mono.fromCallable(() -&gt; { Thread.sleep(1000); return "delayed"; });

// 논블로킹 (수정)
return Mono.delay(Duration.ofSeconds(1)).thenReturn("delayed");</code></pre>
<p><strong>패턴 3: 동기 HTTP 호출</strong></p>
<pre class="highlight"><code class="language-java">// 블로킹 (위험) - RestTemplate 사용
ExternalData data = restTemplate.getForObject(url, ExternalData.class);
return Mono.justOrEmpty(data);

// 논블로킹 (수정) - WebClient 사용
return webClient.get().uri(url).retrieve().bodyToMono(ExternalData.class);</code></pre>
<p><strong>패턴 4: JDBC 호출</strong></p>
<pre class="highlight"><code class="language-java">// 블로킹 (위험)
return Mono.justOrEmpty(jdbcTemplate.queryForObject(sql, mapper, id));

// 논블로킹 (수정 방법 1: boundedElastic으로 격리)
return Mono.fromCallable(() -&gt; jdbcTemplate.queryForObject(sql, mapper, id))
    .subscribeOn(Schedulers.boundedElastic());

// 논블로킹 (수정 방법 2: R2DBC 사용 - Chapter 15 참조)
return r2dbcUserRepository.findById(id);</code></pre>
<h3 id="1953-blockhound">19.5.3 BlockHound 커스텀 설정과 테스트 활용</h3>
<p>특정 라이브러리의 블로킹 호출을 허용하거나, 커스텀 탐지 규칙을 추가할 수 있다.</p>
<pre class="highlight"><code class="language-java">@BeforeAll
static void setup() {
    BlockHound.install(builder -&gt; builder
        // 특정 클래스/메서드의 블로킹 허용 (레거시 라이브러리 등)
        .allowBlockingCallsInside(
            "com.example.legacy.LegacyService", "initialize")
        // 특정 스레드 이름 패턴 제외
        .nonBlockingThreadPredicate(current -&gt;
            current.or(t -&gt; t.getName().startsWith("blocking-worker")))
    );
}</code></pre>
<p>StepVerifier와 BlockHound를 결합하여 블로킹 호출을 자동으로 검출하는 테스트를 작성한다.</p>
<pre class="highlight"><code class="language-java">@SpringBootTest
class ProductServiceBlockingTest {

    @BeforeAll
    static void setup() {
        BlockHound.install();
    }

    @Autowired
    private ProductService productService;

    @Test
    void findById_논블로킹_검증() {
        StepVerifier.create(
            Mono.defer(() -&gt; productService.findById("test-id"))
                .subscribeOn(Schedulers.parallel())  // 논블로킹 스레드에서 실행
        )
        .expectNextCount(1)
        .verifyComplete();
        // 블로킹 호출이 있으면 ReactorBlockHoundIntegration 예외 발생
    }
}</code></pre>
<blockquote>
<p><strong>참고</strong>: BlockHound는 JVM Agent 방식으로 동작하므로 프로덕션 환경에서는 사용하지 않는다. 오버헤드가 발생하며, 의도적인 블로킹(초기화 등)에서도 예외가 발생할 수 있다. 테스트와 스테이징 환경에서만 활성화한다.</p>
</blockquote>
<hr>
<h2 id="196-gatling-k6">19.6 부하 테스트 (Gatling, k6)</h2>
<p>성능 최적화의 효과를 검증하려면 실제 부하 조건에서 테스트해야 한다.</p>
<h3 id="1961-gatling">19.6.1 Gatling 부하 테스트</h3>
<p>Gatling은 Scala 기반의 고성능 부하 테스트 도구다. Java DSL로도 시나리오를 작성할 수 있다.</p>
<pre class="highlight"><code class="language-groovy">plugins {
    id 'io.gatling.gradle' version '3.11.5.2'
}

dependencies {
    gatlingImplementation 'io.gatling.highcharts:gatling-charts-highcharts:3.11.5'
}</code></pre>
<pre class="highlight"><code class="language-java">// src/gatling/java/simulations/ProductApiSimulation.java
public class ProductApiSimulation extends Simulation {

    HttpProtocolBuilder httpProtocol = http
        .baseUrl("http://localhost:8080")
        .acceptHeader("application/json")
        .contentTypeHeader("application/json");

    ScenarioBuilder listProducts = scenario("제품 목록 조회")
        .exec(
            http("GET /api/products")
                .get("/api/products")
                .queryParam("page", "0")
                .queryParam("size", "20")
                .check(status().is(200))
        )
        .pause(Duration.ofMillis(100), Duration.ofMillis(500));

    ScenarioBuilder createProduct = scenario("제품 등록")
        .exec(
            http("POST /api/products")
                .post("/api/products")
                .body(StringBody("""
                    {"name":"테스트 상품","price":10000,"category":"electronics"}
                    """))
                .check(status().is(201))
        )
        .pause(Duration.ofMillis(200), Duration.ofMillis(1000));

    {
        setUp(
            listProducts.injectOpen(
                rampUsersPerSec(10).to(200).during(Duration.ofMinutes(2)),
                constantUsersPerSec(200).during(Duration.ofMinutes(3)),
                rampUsersPerSec(200).to(500).during(Duration.ofMinutes(2)),
                constantUsersPerSec(500).during(Duration.ofMinutes(3))
            ),
            createProduct.injectOpen(
                constantUsersPerSec(20).during(Duration.ofMinutes(10))
            )
        ).protocols(httpProtocol)
         .assertions(
             global().responseTime().percentile3().lt(500),
             global().successfulRequests().percent().gt(99.0)
         );
    }
}</code></pre>
<h3 id="1962-k6">19.6.2 k6 부하 테스트</h3>
<p>k6는 Go로 작성된 현대적인 부하 테스트 도구다. JavaScript로 테스트 스크립트를 작성하며, CLI 기반으로 간편하게 실행할 수 있다.</p>
<pre class="highlight"><code class="language-javascript">// load-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate, Trend } from 'k6/metrics';

const errorRate = new Rate('errors');
const productListDuration = new Trend('product_list_duration');

export const options = {
    stages: [
        { duration: '1m', target: 50 },
        { duration: '3m', target: 200 },
        { duration: '2m', target: 500 },
        { duration: '3m', target: 500 },
        { duration: '1m', target: 0 },
    ],
    thresholds: {
        http_req_duration: ['p(95)&lt;500', 'p(99)&lt;1000'],
        errors: ['rate&lt;0.01'],
    },
};

const BASE_URL = 'http://localhost:8080';

export default function () {
    const listRes = http.get(`${BASE_URL}/api/products?page=0&amp;size=20`);
    productListDuration.add(listRes.timings.duration);

    check(listRes, {
        'status is 200': (r) =&gt; r.status === 200,
        'response time &lt; 500ms': (r) =&gt; r.timings.duration &lt; 500,
    });
    errorRate.add(listRes.status !== 200);
    sleep(Math.random() * 0.5);

    const createRes = http.post(
        `${BASE_URL}/api/products`,
        JSON.stringify({ name: `상품 ${Date.now()}`, price: 10000, category: 'test' }),
        { headers: { 'Content-Type': 'application/json' } }
    );
    check(createRes, { 'created': (r) =&gt; r.status === 201 });
    sleep(Math.random() * 1);
}</code></pre>
<pre class="highlight"><code class="language-bash"># 실행
k6 run load-test.js

# Grafana 연동 (InfluxDB로 메트릭 전송)
k6 run --out influxdb=http://localhost:8086/k6 load-test.js</code></pre>
<h3 id="1963-mvc-vs-webflux">19.6.3 MVC vs WebFlux 성능 비교</h3>
<p>동일한 비즈니스 로직에 대해 Spring MVC와 Spring WebFlux의 성능을 비교한 일반적인 결과는 다음과 같다. 실제 수치는 하드웨어와 비즈니스 로직에 따라 달라진다.</p>
<table>
<thead>
<tr>
<th>지표</th>
<th>Spring MVC</th>
<th>Spring WebFlux</th>
<th>비고</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>동시 사용자 100명</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>처리량</td>
<td>~5,000 req/sec</td>
<td>~6,000 req/sec</td>
<td>유사</td>
</tr>
<tr>
<td>p95 지연시간</td>
<td>~20ms</td>
<td>~18ms</td>
<td>유사</td>
</tr>
<tr>
<td>스레드 수</td>
<td>~200</td>
<td>~8</td>
<td>WebFlux 압도적</td>
</tr>
<tr>
<td>메모리 사용량</td>
<td>~512MB</td>
<td>~256MB</td>
<td>WebFlux 절반</td>
</tr>
<tr>
<td><strong>동시 사용자 1,000명</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>처리량</td>
<td>~4,500 req/sec</td>
<td>~9,000 req/sec</td>
<td>WebFlux 2배</td>
</tr>
<tr>
<td>p95 지연시간</td>
<td>~250ms</td>
<td>~50ms</td>
<td>WebFlux 5배</td>
</tr>
<tr>
<td>스레드 수</td>
<td>~1,000+</td>
<td>~8</td>
<td>WebFlux 압도적</td>
</tr>
<tr>
<td><strong>동시 사용자 5,000명</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>처리량</td>
<td>~3,000 req/sec</td>
<td>~8,500 req/sec</td>
<td>WebFlux 3배</td>
</tr>
<tr>
<td>p95 지연시간</td>
<td>~2,000ms+</td>
<td>~120ms</td>
<td>WebFlux 16배</td>
</tr>
<tr>
<td>에러율</td>
<td>~5%</td>
<td>~0.1%</td>
<td>MVC 커넥션 거부</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>핵심 포인트</strong>: 동시 사용자가 적을 때는 MVC와 WebFlux의 성능 차이가 크지 않다. WebFlux의 진가는 <strong>높은 동시성</strong> 상황에서 발휘된다. I/O 대기 시간이 긴 애플리케이션(외부 API 호출, 느린 DB 쿼리)일수록 WebFlux의 이점이 두드러진다.</p>
</blockquote>
<h3 id="1964">19.6.4 부하 테스트 결과 분석 체크리스트</h3>
<table>
<thead>
<tr>
<th>점검 항목</th>
<th>정상 기준</th>
<th>이상 시 대응</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>p95 응답 시간</strong></td>
<td>SLA 목표 이내</td>
<td>병목 구간 프로파일링</td>
</tr>
<tr>
<td><strong>에러율</strong></td>
<td>&lt; 0.1%</td>
<td>에러 로그 분석, 타임아웃 조정</td>
</tr>
<tr>
<td><strong>CPU 사용률</strong></td>
<td>&lt; 80%</td>
<td>스케줄러 오프로드, 알고리즘 최적화</td>
</tr>
<tr>
<td><strong>메모리 사용률</strong></td>
<td>GC 오버헤드 &lt; 5%</td>
<td>힙 크기 조정, 객체 풀링</td>
</tr>
<tr>
<td><strong>커넥션 풀 대기</strong></td>
<td>waitQueue = 0</td>
<td>풀 크기 증가, 쿼리 최적화</td>
</tr>
<tr>
<td><strong>이벤트 루프 CPU</strong></td>
<td>각 스레드 &lt; 70%</td>
<td>블로킹 코드 제거, 연산 오프로드</td>
</tr>
</tbody>
</table>
<h3 id="1965">19.6.5 성능 최적화 사이클</h3>
<p>성능 최적화는 일회성이 아니라 반복적인 과정이다.</p>
<pre class="highlight"><code>1. 측정 (Baseline)       &lt;- Gatling/k6로 현재 성능 측정
2. 분석 (Bottleneck)     &lt;- 프로파일링, 메트릭, 로그 분석
3. 최적화 (Fix)          &lt;- 커넥션 풀, 캐시, 블로킹 제거, 쿼리 최적화
4. 검증 (Verify)         &lt;- 동일 조건에서 재측정, 비교
5. 반복 (Iterate)        &lt;- 다음 병목 지점으로 이동</code></pre>
<p>한 번에 여러 최적화를 적용하면 어떤 변경이 효과가 있었는지 판단할 수 없다. <strong>한 번에 하나의 변경만 적용하고 측정하는 것</strong>이 원칙이다.</p>
<hr>
<h2 id="_1">요약</h2>
<table>
<thead>
<tr>
<th>주제</th>
<th>핵심 내용</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>성능 측정</strong></td>
<td>처리량/지연시간/리소스 3축 측정, Micrometer 메트릭, JMH 마이크로벤치마크, async-profiler/JFR 프로파일링</td>
</tr>
<tr>
<td><strong>MongoDB 커넥션 풀</strong></td>
<td><code>MongoClientSettings</code>로 풀 크기/타임아웃 설정, 커넥션 풀 메트릭 모니터링, 계층별 타임아웃 전략</td>
</tr>
<tr>
<td><strong>Netty 이벤트 루프</strong></td>
<td><code>LoopResources</code>로 스레드 수 조정, Epoll/KQueue 네이티브 Transport, 블로킹 작업 스케줄러 오프로드</td>
</tr>
<tr>
<td><strong>캐싱 전략</strong></td>
<td>Caffeine 로컬 캐시, Reactive Redis 분산 캐시, L1/L2 멀티 레벨 캐시 구조</td>
</tr>
<tr>
<td><strong>BlockHound</strong></td>
<td>블로킹 호출 런타임 탐지, 흔한 블로킹 패턴과 수정법, StepVerifier 테스트 통합</td>
</tr>
<tr>
<td><strong>부하 테스트</strong></td>
<td>Gatling/k6 스크립트 작성, MVC vs WebFlux 성능 비교, 결과 분석 체크리스트, 최적화 사이클</td>
</tr>
</tbody>
</table>
<p>성능 최적화에서 가장 중요한 것은 <strong>측정 -&gt; 분석 -&gt; 최적화 -&gt; 검증</strong>의 사이클을 반복하는 것이다. 감이 아닌 데이터에 기반한 의사결정이 효과적인 최적화의 핵심이다.</p>
<p>다음 장에서는 애플리케이션의 컨테이너화와 배포를 다루며, Docker 이미지 빌드, Kubernetes 배포, CI/CD 파이프라인 구성을 실습한다.</p>
    </main>
    <footer class="site-footer">
      &copy; 2024 Spring Boot + WebFlux + JPA (MongoDB) Book
    </footer>
  </div>
</body>
</html>